{"cells":[{"cell_type":"markdown","source":["### Tuning Hyperparameters using Grid Search\n\n\nMost machine learning algorithms have a set of parameters that govern the algorithm's behavior.  These parameters are called hyperparameters to distinguish them from the model parameters such as the coefficients in linear and logistic regression.  In this module we show how to use grid search and cross validation in Spark MLlib to determine a reasonable regularization parameter for [L1 lasso linear regression](https://en.wikipedia.org/wiki/Lasso_%28statistics%29). This notebook is based on material supplied by Cloudera under their Cloudera Academic Partner program and *Spark: The Definitive Guide* book by Bill Chambers and Matei Zaharia.\n\nTopics\n- Creating train, validation, and test datasets\n- Prepare for hyperparameter tuning by specifying\n  - Estimator\n  - Hyperparameter grid\n  - Evaluator\n- Tuning hyperparameters using a hold out cross-validation\n- Tuning hyperparameters using k-fold cross-validation\n\nYou can find details of all of the classes, methods, and attributes in the [Spark MLlib API Reference](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html) and a more general guide to their use in the [Machine Learning Library (MLlib) Guide](https://spark.apache.org/docs/latest/ml-guide.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2f21af2-a322-47f8-9cbd-201038e1f056"}}},{"cell_type":"markdown","source":["#### Generate the train and test datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"114f212c-7f80-414a-9843-92c564aa7103"}}},{"cell_type":"code","source":["# Load the regression modeling data  (saved version of \"assembled\" DataFrame from \"Building and Evaluating Classification Models\" notebook)\nrides = spark.read.parquet(\"/mnt/my-data/duocar/regression_data\")\n\n# Just renaming columns for clearer printing\n# not changing the names them for our analysis\nrides\\\n  .withColumnRenamed(\"vehicle_year\", \"year\")\\\n  .withColumnRenamed(\"star_rating\", \"star\")\\\n  .withColumnRenamed(\"high_rating\", \"high\")\\\n  .show(3, False)\n\n# Create train and test DataFrames\n(train, test) = rides.randomSplit([0.7, 0.3], 12345)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b8378ab-7d77-4634-a65e-4141da2fa953"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+----+----------------+----+----+-----------------------+\n|reviewed|year|vehicle_color_cd|star|high|features               |\n+--------+----+----------------+----+----+-----------------------+\n|0       |2015|(9,[1],[1.0])   |5.0 |1.0 |(11,[1,3],[2015.0,1.0])|\n|0       |2015|(9,[0],[1.0])   |5.0 |1.0 |(11,[1,2],[2015.0,1.0])|\n|0       |2015|(9,[1],[1.0])   |5.0 |1.0 |(11,[1,3],[2015.0,1.0])|\n+--------+----+----------------+----+----+-----------------------+\nonly showing top 3 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+----+----------------+----+----+-----------------------+\nreviewed|year|vehicle_color_cd|star|high|features               |\n+--------+----+----------------+----+----+-----------------------+\n0       |2015|(9,[1],[1.0])   |5.0 |1.0 |(11,[1,3],[2015.0,1.0])|\n0       |2015|(9,[0],[1.0])   |5.0 |1.0 |(11,[1,2],[2015.0,1.0])|\n0       |2015|(9,[1],[1.0])   |5.0 |1.0 |(11,[1,3],[2015.0,1.0])|\n+--------+----+----------------+----+----+-----------------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# display(dbutils.fs.ls(\"dbfs:/mnt/my-data/duocar\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5ecc276-7cad-4acb-9d72-1dc24bcf1a9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Requirements for hyperparameter tuning\n\nWe need to specify four components to perform hyperparameter tuning using grid search:\n1. Estimator\n2. Hyperparameter grid\n3. Evaluator\n4. Validation method"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7f829bc-6af0-426f-9c1a-9a6fe33c3b2e"}}},{"cell_type":"markdown","source":["#### Specify the estimator\n\nIn this example we will use L1 (lasso) linear regression as our estimator."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7188ec2c-c993-480c-ab38-68186b06e6ad"}}},{"cell_type":"code","source":["# Setting `elasticNetParam=1.0` corresponds to L1 (lasso) linear regression\n# Setting `elasticNetParam-0.0` would be L2 (ridge) linear regression\n# We are interested in finding a good value of the Regualarization Parameter `regParam` \n\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"star_rating\", elasticNetParam=1.0)\n\n# Use the `explainParams` method to get the full list of hyperparameters as wall as training parameters:\nprint(lr.explainParams())"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56b44bb0-9105-4866-b4ca-2dbfec0ea007"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">aggregationDepth: suggested depth for treeAggregate (&gt;= 2). (default: 2)\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 1.0)\nepsilon: The shape parameter to control the amount of robustness. Must be &gt; 1.0. Only valid when loss is huber (default: 1.35)\nfeaturesCol: features column name. (default: features, current: features)\nfitIntercept: whether to fit an intercept term. (default: True)\nlabelCol: label column name. (default: label, current: star_rating)\nloss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\nmaxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be &gt;= 0. (default: 0.0)\nmaxIter: max number of iterations (&gt;= 0). (default: 100)\npredictionCol: prediction column name. (default: prediction)\nregParam: regularization parameter (&gt;= 0). (default: 0.0)\nsolver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto)\nstandardization: whether to standardize the training features before fitting the model. (default: True)\ntol: the convergence tolerance for iterative algorithms (&gt;= 0). (default: 1e-06)\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">aggregationDepth: suggested depth for treeAggregate (&gt;= 2). (default: 2)\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0, current: 1.0)\nepsilon: The shape parameter to control the amount of robustness. Must be &gt; 1.0. Only valid when loss is huber (default: 1.35)\nfeaturesCol: features column name. (default: features, current: features)\nfitIntercept: whether to fit an intercept term. (default: True)\nlabelCol: label column name. (default: label, current: star_rating)\nloss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\nmaxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be &gt;= 0. (default: 0.0)\nmaxIter: max number of iterations (&gt;= 0). (default: 100)\npredictionCol: prediction column name. (default: prediction)\nregParam: regularization parameter (&gt;= 0). (default: 0.0)\nsolver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto)\nstandardization: whether to standardize the training features before fitting the model. (default: True)\ntol: the convergence tolerance for iterative algorithms (&gt;= 0). (default: 1e-06)\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Specify hyperparameter grid\n\nUse the [ParamGridBuilder](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html) class to specify a hyperparameter grid.\n\n- `addGrid (param, values)` Sets the given parameters in the grid to fixed values\n- `baseOn (*args)` Sets the given parameters in this grid to fixed values. Accepts either a parameter dictionary or a list of (parameter, value) pairs\n- `build()`  builds and returns all combinations of parameters specified by the param grid."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"429af8ac-530a-40c2-8a05-29645c21a49e"}}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\nregParamList = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\ngrid = ParamGridBuilder().addGrid(lr.regParam, regParamList).build()\n\n# The resulting object is simply a list of parameter maps\nfor item in grid:\n    print(item)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"552ce0dc-08e6-4e11-9163-d5a75e716512"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.0}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.2}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.3}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.4}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.5}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.0}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.2}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.3}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.4}\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.5}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["type (grid)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a3ee3b4-2c44-4854-8ddd-2fac684e4e25"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[32]: list</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[32]: list</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Rather than specify `elasticNetParam` in the `LinearRegression` constructor, we can specify it in our grid\ngrid = ParamGridBuilder().baseOn({lr.elasticNetParam: 1.0}).addGrid(lr.regParam, regParamList).build()"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4fb90f3-2de9-4b11-a19d-bb041a27fac9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# The resulting object is simply a list of parameter maps\n# This time it includes elasticNetParam with a value of 1.0\nfor item in grid:\n    print(item)\n    print (\"\\n\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77aa945a-589c-4e43-b15c-48b7264ecb0a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.0}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.2}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.3}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.4}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.5}\n\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.0}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.2}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.3}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.4}\n\n\n{Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 1.0, Param(parent=&#39;LinearRegression_441366c17570&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.5}\n\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Specify the evaluator\n\nIn this case we will use [RegressionEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html) as our evaluator and specify root-mean-squared error (rmse) as the evaluatoin metric. Ohter machine learning algorighms have suitable evaluators."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cae7368-2152-4dc3-bd15-43ca7dc49aca"}}},{"cell_type":"code","source":["# Use RegressionEvaluator as our evaluator and specify root-mean-squared error as the metric\nfrom pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"star_rating\", metricName=\"rmse\")"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a186abc-4bd6-4528-9968-a32af672f7c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Tuning the hyperparameters using holdout cross-validation\n\n[TrainValidationSplit](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.TrainValidationSplit.html) supports validation for hyper-parameter tuning. We use it to specify a holdout dataset for cross-validation.  It randomly splits the input dataset into train and validation sets, and uses the `evaluation metric` on the validation set to select the best model. It is similar to `CrossValidator`, but only splits the set once. For large DataFrames, holdout cross-validation is efficient. \n\nNote that in our example \n- We already split the data (above) into a train and test datasets. `TrainValidationSplit` splits the train dataset from that step into new train and validation datasets\n- The models for each combination of hyperparameters will be fit using the new smaller training dataset\n- Each of those models will be evaluated using the `evaluation metric` on the validation dataset to select the best model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0432127a-aa7e-4851-97d5-2ee7b69bb53e"}}},{"cell_type":"code","source":["# Use the `TrainValidationSplit` class to specify holdout cross-validation\nfrom pyspark.ml.tuning import TrainValidationSplit\nvalidator = TrainValidationSplit(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, trainRatio=0.75, seed=54321)\n\n# Use the `fit` method to find the best set of hyperparameters\n# The dataset will be split according to `trainRatio` \ncv_model = validator.fit(train)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6bbb2284-9eb9-4a8a-bee4-7ae2fcdc9412"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The resulting model is an instance of the [TrainValidationSplitModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.TrainValidationSplitModel.html) class."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e6eff6e-8d9f-4d11-8e7f-85e77b55600b"}}},{"cell_type":"code","source":["# Confirm type of model returned from TrainValidationSplit class\ntype(cv_model)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"721ffff3-c60f-40ee-8193-9bf3e0224a8d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[37]: pyspark.ml.tuning.TrainValidationSplitModel</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[37]: pyspark.ml.tuning.TrainValidationSplitModel</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# The cross-validation results are stored in the `validationMetrics` attribute\ncv_model.validationMetrics\n\n# These are the rmse errors (smaller is better) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e7b4cf6-cb08-4899-bf35-758fd2426bc7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[38]: [1.0995311645849588,\n 1.109470369357201,\n 1.1327856354695602,\n 1.1481376494959807,\n 1.1481376494959807,\n 1.1481376494959807]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[38]: [1.0995311645849588,\n 1.109470369357201,\n 1.1327856354695602,\n 1.1481376494959807,\n 1.1481376494959807,\n 1.1481376494959807]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Plot Validation Metric (rmse) against  Regularization Parameter"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eca024ce-8ed5-44d1-b37a-20bbf0adb37a"}}},{"cell_type":"code","source":["# Zip the two lists together and create a dataframe for plotting\nto_plot = zip(regParamList,cv_model.validationMetrics)\nto_plot_df = spark.createDataFrame(to_plot, \\\n             schema=[\"Regularization_Param\", \"Validation_Metric (rmse)\"])\nto_plot_df.printSchema()"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"076cb70c-6bd3-4c4c-8630-31e2740eb89d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- Regularization_Param: double (nullable = true)\n |-- Validation_Metric (rmse): double (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Regularization_Param: double (nullable = true)\n-- Validation_Metric (rmse): double (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["display(to_plot_df)\n# x-axis Regularization Parameter\n# y-axis Validation Metric (rmse)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Validation Metric (rmse) against value of Regularization Parameter","showTitle":false,"inputWidgets":{},"nuid":"7e9ca348-5b35-42a4-9137-e3614b54623f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[0.0,1.0995311645849588],[0.1,1.109470369357201],[0.2,1.1327856354695602],[0.3,1.1481376494959807],[0.4,1.1481376494959807],[0.5,1.1481376494959807]],"plotOptions":{"displayType":"mgLine","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Regularization_Param","type":"\"double\"","metadata":"{}"},{"name":"Validation_Metric (rmse)","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Regularization_Param</th><th>Validation_Metric (rmse)</th></tr></thead><tbody><tr><td>0.0</td><td>1.0995311645849588</td></tr><tr><td>0.1</td><td>1.109470369357201</td></tr><tr><td>0.2</td><td>1.1327856354695602</td></tr><tr><td>0.3</td><td>1.1481376494959807</td></tr><tr><td>0.4</td><td>1.1481376494959807</td></tr><tr><td>0.5</td><td>1.1481376494959807</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The best performance was with the regularization parameter at zero (i.e. Linear Regression)\nHowever, it might be worth exploring the space between 0 and 0.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a78d3810-dd3d-4b2d-bb95-21a38d93384b"}}},{"cell_type":"markdown","source":["In this case the `bestModel` attribute is an instance of the [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionModel.html) class. \n\n**Note:** \n- The model is rerun on the entire dataset using the best set of hyperparameters\n- The usual attributes and methods of the `LinearRegressionModel` are available  (so we can look at performance measures, coefficients, etc.)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89dc4011-7888-415e-8a79-f5743ae32649"}}},{"cell_type":"code","source":["# Show type of 'bestModel'\ntype(cv_model.bestModel)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a74f6af8-5041-4eb6-82d6-9275da0085f2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[41]: pyspark.ml.regression.LinearRegressionModel</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[41]: pyspark.ml.regression.LinearRegressionModel</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# A function for printing common results of a linear regression model\n# Note that this is a prototype. In its current form it will not handle\n# models without an intercept. Works okay for this example\nfrom pyspark.sql.types import *\nimport pandas as pd\ndef printLinRegResults(model, feature_list):\n    # Query model performance:\n    print (\"R-Squared: \" + str(model.summary.r2))\n    print (\"RMSE:     \" + str(model.summary.rootMeanSquaredError))\n    \n    # Build a list of model coefficients with native python float types\n    combined_coeff = []\n    coeff_floats = [round(float(np_float),5) for np_float in model.coefficients] # convert coefficients to floats\n    combined_coeff.extend((coeff_floats)) # Add the coefficients to the list\n    combined_coeff.append(round(float(model.intercept),5)) # Append the intecept to the list of coefficients\n    \n    StandardErrors = [round(num, 5) for num in model.summary.coefficientStandardErrors]\n    tValues = [round(num, 5) for num in model.summary.tValues]\n    pValues = [round(num, 5) for num in model.summary.pValues]\n    \n    model_summary = list(zip(feature_list, combined_coeff, StandardErrors, tValues, pValues))\n    df = pd.DataFrame(model_summary, columns = ['Feature', 'Coefficientt', 'Standard Error', 't-value', 'p-value'])\n    print(\"Note: Last row of this table represents the intercept\")\n    print(df)\n    #display(df)    "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0788138b-7202-4c74-88a6-45eb6f8210d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Show results of model by passing the model \n# and the feature list to the function\nfeatures_list = ['reviewed', 'vehicle_year', 'black', 'white', \\\n                 'gray', 'silver', 'blue', 'red', 'yellow', \\\n                 'green', 'brown', 'intercept']\nprintLinRegResults(cv_model.bestModel, features_list)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8588086b-77f8-41dc-ba62-fe65df5d6763"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">R-Squared: 0.09233264758083592\nRMSE:     1.0831058003196994\nNote: Last row of this table represents the intercept\n         Feature  Coefficientt  Standard Error   t-value  p-value\n0       reviewed      -1.26669         0.03062 -41.36974  0.00000\n1   vehicle_year       0.04214         0.00151  27.90144  0.00000\n2          black       0.06335         0.04319   1.46686  0.14242\n3          white      -0.02846         0.04565  -0.62354  0.53294\n4           gray      -0.00066         0.04660  -0.01417  0.98870\n5         silver      -0.01348         0.04726  -0.28517  0.77552\n6           blue      -0.02347         0.04935  -0.47555  0.63440\n7            red       0.03849         0.05081   0.75743  0.44880\n8         yellow      -0.48630         0.05525  -8.80222  0.00000\n9          green      -0.00410         0.05580  -0.07342  0.94147\n10         brown       0.00888         0.05870   0.15127  0.87976\n11     intercept     -80.46167         3.04201 -26.45016  0.00000\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">R-Squared: 0.09233264758083592\nRMSE:     1.0831058003196994\nNote: Last row of this table represents the intercept\n         Feature  Coefficientt  Standard Error   t-value  p-value\n0       reviewed      -1.26669         0.03062 -41.36974  0.00000\n1   vehicle_year       0.04214         0.00151  27.90144  0.00000\n2          black       0.06335         0.04319   1.46686  0.14242\n3          white      -0.02846         0.04565  -0.62354  0.53294\n4           gray      -0.00066         0.04660  -0.01417  0.98870\n5         silver      -0.01348         0.04726  -0.28517  0.77552\n6           blue      -0.02347         0.04935  -0.47555  0.63440\n7            red       0.03849         0.05081   0.75743  0.44880\n8         yellow      -0.48630         0.05525  -8.80222  0.00000\n9          green      -0.00410         0.05580  -0.07342  0.94147\n10         brown       0.00888         0.05870   0.15127  0.87976\n11     intercept     -80.46167         3.04201 -26.45016  0.00000\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Tune hyperparameters using k-fold cross-validation\n\nUse the [CrossValidator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html) class to specify the k-fold cross-validation. K-fold cross validation performs model selection by splitting the dataset into a set of non-overlapping randomly partitioned folds which are used as separate training and test datasets e.g., with k=3 folds, K-fold cross validation will generate 3 (training, test) dataset pairs, each of which uses 2/3 of the data for training and 1/3 for testing. Each fold is used as the test set exactly once. For small datasets k-fold cross-validation will be more accurate.\n\nThe result is an instance of the [CrossValidatorModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidatorModel.html) class."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d2563e7-b1f7-4585-bea6-dfbdd63d5f41"}}},{"cell_type":"code","source":["# Use the CrossValidator class to specify the k-fold cross-validation\nfrom pyspark.ml.tuning import CrossValidator\nkfold_validator = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, numFolds=3, seed=54321)\nkfold_model = kfold_validator.fit(train)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7dc4244-cbe7-4236-9033-bb2207542110"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Check type of resulting class\ntype(kfold_model)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a16c5fcc-94e9-4a7b-8e80-4218313ae4c2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[45]: pyspark.ml.tuning.CrossValidatorModel</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[45]: pyspark.ml.tuning.CrossValidatorModel</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# The cross-validation results are stored in the `avgMetrics` attribute\nkfold_model.avgMetrics\n\n# These are the rmse errors (smaller is better) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51d770a4-349c-4ee4-af1a-65d7281a2347"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[46]: [1.0836731652226863,\n 1.0958841775631103,\n 1.121649513739378,\n 1.136854244478132,\n 1.136854244478132,\n 1.136854244478132]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: [1.0836731652226863,\n 1.0958841775631103,\n 1.121649513739378,\n 1.136854244478132,\n 1.136854244478132,\n 1.136854244478132]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Plot Validation Metric (rmse) against  Regularization Parameter"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28ed9b3c-99f2-47a5-aaa8-67716b75efad"}}},{"cell_type":"code","source":["to_plot2 = zip(regParamList,kfold_model.avgMetrics)\nto_plot_df2 = spark.createDataFrame(to_plot2, schema=[\"Regularization_Param\", \"Validation_Metric\"])\n\n# The best performance was with the regularization parameter at zero (i.e. Linear Regression)\n# However, it might be worth exploring the space between 0 and 0.1 "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8747349-c4aa-4f70-b2d3-825f65532e62"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["display(to_plot_df2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Validation Metric (rmse) against value of Regularization Parameter","showTitle":false,"inputWidgets":{},"nuid":"f267d78b-73d8-42e8-b8fa-acd907344369"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[0.0,1.0836731652226863],[0.1,1.0958841775631103],[0.2,1.121649513739378],[0.3,1.136854244478132],[0.4,1.136854244478132],[0.5,1.136854244478132]],"plotOptions":{"displayType":"mgLine","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Regularization_Param","type":"\"double\"","metadata":"{}"},{"name":"Validation_Metric","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Regularization_Param</th><th>Validation_Metric</th></tr></thead><tbody><tr><td>0.0</td><td>1.0836731652226863</td></tr><tr><td>0.1</td><td>1.0958841775631103</td></tr><tr><td>0.2</td><td>1.121649513739378</td></tr><tr><td>0.3</td><td>1.136854244478132</td></tr><tr><td>0.4</td><td>1.136854244478132</td></tr><tr><td>0.5</td><td>1.136854244478132</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# The `bestModel` attribute contains the model based on the best set of hyperparameters.\n# In this case, it is an instance of the `LinearRegressionModel` class\ntype(kfold_model.bestModel)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20c53616-7c15-49fc-87f1-de11a5c2d262"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[49]: pyspark.ml.regression.LinearRegressionModel</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[49]: pyspark.ml.regression.LinearRegressionModel</div>"]}}],"execution_count":0},{"cell_type":"code","source":["printLinRegResults(kfold_model.bestModel, features_list)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f6ac818-7c83-47a9-a1a9-15aeb4e22020"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">R-Squared: 0.09233264758083592\nRMSE:     1.0831058003196994\nNote: Last row of this table represents the intercept\n         Feature  Coefficientt  Standard Error   t-value  p-value\n0       reviewed      -1.26669         0.03062 -41.36974  0.00000\n1   vehicle_year       0.04214         0.00151  27.90144  0.00000\n2          black       0.06335         0.04319   1.46686  0.14242\n3          white      -0.02846         0.04565  -0.62354  0.53294\n4           gray      -0.00066         0.04660  -0.01417  0.98870\n5         silver      -0.01348         0.04726  -0.28517  0.77552\n6           blue      -0.02347         0.04935  -0.47555  0.63440\n7            red       0.03849         0.05081   0.75743  0.44880\n8         yellow      -0.48630         0.05525  -8.80222  0.00000\n9          green      -0.00410         0.05580  -0.07342  0.94147\n10         brown       0.00888         0.05870   0.15127  0.87976\n11     intercept     -80.46167         3.04201 -26.45016  0.00000\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">R-Squared: 0.09233264758083592\nRMSE:     1.0831058003196994\nNote: Last row of this table represents the intercept\n         Feature  Coefficientt  Standard Error   t-value  p-value\n0       reviewed      -1.26669         0.03062 -41.36974  0.00000\n1   vehicle_year       0.04214         0.00151  27.90144  0.00000\n2          black       0.06335         0.04319   1.46686  0.14242\n3          white      -0.02846         0.04565  -0.62354  0.53294\n4           gray      -0.00066         0.04660  -0.01417  0.98870\n5         silver      -0.01348         0.04726  -0.28517  0.77552\n6           blue      -0.02347         0.04935  -0.47555  0.63440\n7            red       0.03849         0.05081   0.75743  0.44880\n8         yellow      -0.48630         0.05525  -8.80222  0.00000\n9          green      -0.00410         0.05580  -0.07342  0.94147\n10         brown       0.00888         0.05870   0.15127  0.87976\n11     intercept     -80.46167         3.04201 -26.45016  0.00000\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Compute the performance of the best model on the test dataset\nsummary_test = kfold_model.bestModel.evaluate(test)\n\nprint (\"R-Squared: \" + str(summary_test.r2))\nprint (\"RMSE:     \" + str(summary_test.rootMeanSquaredError))\n\nprint(type(summary_test))"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b0b20fd-d7eb-4c26-9186-6f35c0966ab4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">R-Squared: 0.09445675782345075\nRMSE:     1.0829997589339142\n&lt;class &#39;pyspark.ml.regression.LinearRegressionSummary&#39;&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">R-Squared: 0.09445675782345075\nRMSE:     1.0829997589339142\n&lt;class &#39;pyspark.ml.regression.LinearRegressionSummary&#39;&gt;\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Show come of the predicions (used sampleBy to ensure I got some rides with reviews)\nsummary_test.predictions.sampleBy(\"reviewed\", fractions={0:0.00025, 1:0.05}, seed = 42)\\\n  .drop(\"features\")\\\n  .withColumnRenamed(\"reviewed\",\"rev\")\\\n  .withColumnRenamed(\"vehicle_year\",\"year\")\\\n  .withColumnRenamed(\"vehicle_color_cd\",\"color\")\\\n  .withColumnRenamed(\"star_rating\",\"star\")\\\n  .withColumnRenamed(\"high_rating\",\"high\")\\\n  .show(10, False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d604f7c4-b313-4f2e-9a31-4102e72f8edd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---+----+-------------+----+----+------------------+\n|rev|year|color        |star|high|prediction        |\n+---+----+-------------+----+----+------------------+\n|0  |2015|(9,[0],[1.0])|5.0 |1.0 |4.50774257706631  |\n|0  |2016|(9,[0],[1.0])|4.0 |0.0 |4.549879582025767 |\n|1  |2002|(9,[1],[1.0])|2.0 |0.0 |2.601455876889162 |\n|1  |2002|(9,[2],[1.0])|1.0 |0.0 |2.629258042677151 |\n|1  |2002|(9,[2],[1.0])|2.0 |0.0 |2.629258042677151 |\n|1  |2002|(9,[4],[1.0])|3.0 |0.0 |2.606451748139108 |\n|1  |2003|(9,[2],[1.0])|1.0 |0.0 |2.671395047636622 |\n|1  |2003|(9,[6],[1.0])|1.0 |0.0 |2.185754397519119 |\n|1  |2005|(9,[2],[1.0])|2.0 |0.0 |2.7556690575555365|\n|1  |2007|(9,[0],[1.0])|3.0 |0.0 |2.9039553799126736|\n+---+----+-------------+----+----+------------------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----+-------------+----+----+------------------+\nrev|year|color        |star|high|prediction        |\n+---+----+-------------+----+----+------------------+\n0  |2015|(9,[0],[1.0])|5.0 |1.0 |4.50774257706631  |\n0  |2016|(9,[0],[1.0])|4.0 |0.0 |4.549879582025767 |\n1  |2002|(9,[1],[1.0])|2.0 |0.0 |2.601455876889162 |\n1  |2002|(9,[2],[1.0])|1.0 |0.0 |2.629258042677151 |\n1  |2002|(9,[2],[1.0])|2.0 |0.0 |2.629258042677151 |\n1  |2002|(9,[4],[1.0])|3.0 |0.0 |2.606451748139108 |\n1  |2003|(9,[2],[1.0])|1.0 |0.0 |2.671395047636622 |\n1  |2003|(9,[6],[1.0])|1.0 |0.0 |2.185754397519119 |\n1  |2005|(9,[2],[1.0])|2.0 |0.0 |2.7556690575555365|\n1  |2007|(9,[0],[1.0])|3.0 |0.0 |2.9039553799126736|\n+---+----+-------------+----+----+------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Hands On\n\n![Hands-on](https://cis442f-open-data.s3.amazonaws.com/pictures/hands.png \"Hands-on\")\n\n\n#### Exercises\n\n(1) Maybe our regularization parameters are too large.  Rerun the hyperparameter tuning with regularization parameters [0.0, 0.02, 0.04, 0.06, 0.08, 0.01].\n\n(2) Create a parameter grid that searches over regularization type (lasso or ridge) as well as the regularization parameter.\n\n(3) Apply hyperparameter tuning to another learning algorithm (estimator).\n\n\n\n#### References\n\n[Model Selection and hyperparameter tuning](http://spark.apache.org/docs/latest/ml-tuning.html)\n\n[pyspark MLlib tuning](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#tuning)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71277f9a-3e8a-4955-8f2e-7591b83921bb"}}},{"cell_type":"code","source":["# A function for printing common results of a linear regression model\n# Note that this is a prototype. In its current form it will not handle\n# models without an intercept. Works okay for this example\n\n# This version works even if pandas is not available\n\nfrom pyspark.sql.types import *\ndef printLinRegResults(model, feature_list):\n    # Query model performance:\n    print (\"R-Squared: \" + str(model.summary.r2))\n    print (\"RMSE:     \" + str(model.summary.rootMeanSquaredError))\n   \n    # Build a list of model coefficients with native python float types\n    combined_coeff = []\n    coeff_floats = [round(float(np_float),5) for np_float in model.coefficients] # convert coefficients to floats\n    combined_coeff.extend((coeff_floats)) # Add the coefficients to the list\n    combined_coeff.append(round(float(model.intercept),5)) # Append the intecept to the list of coefficients\n    \n    StandardErrors = [round(num, 5) for num in model.summary.coefficientStandardErrors]\n    tValues = [round(num, 5) for num in model.summary.tValues]\n    pValues = [round(num, 5) for num in model.summary.pValues]\n    \n    model_summary2 = list(zip(feature_list, combined_coeff, StandardErrors, tValues, pValues))\n    df = pd.DataFrame(model_summary2, columns = ['Feature', 'Coefficientt', 'Standard Error', 't-value', 'p-value'])\n    display(df)\n\n    # Create a DataFrame with summary of regression results\n    # First define the schema of the DataFrame\n    schema = StructType([StructField(\"Feature\", StringType(), True),\\\n                        StructField(\"Coefficient\", DoubleType(), True),\\\n                        StructField(\"Standard Error\", DoubleType(), True),\\\n                        StructField(\"t-value\", DoubleType(), True),\\\n                        StructField(\"p-value\", DoubleType(), True)])\n  \n    # zip the elements of the various lists together and create a DataFrame\n    model_summary = zip(feature_list, combined_coeff, StandardErrors, tValues, pValues)\n    to_print_df = spark.createDataFrame(model_summary, schema=schema)\n    print(\"Note: Last row of this table represents the intercept\")\n    to_print_df.show()\n    \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0099ecc-5af1-4465-bb19-97de21bb8a99"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# This helped me confirm that I was including the right colors when displaying the  results using the function I defined\nrides.groupBy(\"vehicle_color_cd\").count().orderBy(\"vehicle_color_cd\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4da91e5d-d182-4108-8e6a-a0a2fc847cd6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------+-----+\n|vehicle_color_cd|count|\n+----------------+-----+\n|       (9,[],[])|  972|\n|   (9,[0],[1.0])|20892|\n|   (9,[1],[1.0])| 6486|\n|   (9,[2],[1.0])| 4678|\n|   (9,[3],[1.0])| 4041|\n|   (9,[4],[1.0])| 2797|\n|   (9,[5],[1.0])| 2365|\n|   (9,[6],[1.0])| 1313|\n|   (9,[7],[1.0])| 1279|\n|   (9,[8],[1.0])| 1018|\n+----------------+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------+-----+\nvehicle_color_cd|count|\n+----------------+-----+\n       (9,[],[])|  972|\n   (9,[0],[1.0])|20892|\n   (9,[1],[1.0])| 6486|\n   (9,[2],[1.0])| 4678|\n   (9,[3],[1.0])| 4041|\n   (9,[4],[1.0])| 2797|\n   (9,[5],[1.0])| 2365|\n   (9,[6],[1.0])| 1313|\n   (9,[7],[1.0])| 1279|\n   (9,[8],[1.0])| 1018|\n+----------------+-----+\n\n</div>"]}}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Spark 2.0.0 - Scala 2.11","language":"scala","name":"spark2-scala"},"language_info":{"mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","codemirror_mode":"text/x-scala","version":"2.11.8","file_extension":".scala"},"application/vnd.databricks.v1+notebook":{"notebookName":"12b. Tuning Hyperparameters using Grid Search","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3957930297147875}},"nbformat":4,"nbformat_minor":0}
