{"cells":[{"cell_type":"markdown","source":["### Transforming DataFrame Columns in Spark\n\nIn this notebook we demonstrate how to transform DataFrame columns. It is based on material supplied by Cloudera under their Cloudera Academic Partner program and the *Spark: The Definitive Guide* book by Bill Chambers and Matei Zaharia. \n\nTopics\n- Working with numerical columns\n- Working with string columns\n- Working with datetime columns\n- Working with Boolean columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87c6f2fa-bf24-4594-b2c9-4d533c53f098"}}},{"cell_type":"code","source":["# Load the raw rides data:\nrides = spark.read.csv(\"/mnt/cis442f-data/duocar/raw/rides/\", header=True, inferSchema=True)\n\n# Load the raw driver data:\ndrivers = spark.read.csv(\"/mnt/cis442f-data/duocar/raw/drivers\", header=True, inferSchema=True)\n\n# Load the raw rider data:\nriders = spark.read.csv(\"/mnt/cis442f-data/duocar/raw/riders/\", header=True, inferSchema=True)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb8b8c05-f4da-4975-a08e-ae49f499324c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Working with numerical columns\n\n#### Example 1: Converting ride distance from meters to miles\n\n**Notes:**\n- We use the fact that 1 mile = 1609.344 meters\n- We use the `round` function to round the result to two decimal places\n- We use the `alias` method to rename the column"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"142a491f-2f9f-4730-b3d5-100ea94fd150"}}},{"cell_type":"code","source":["from pyspark.sql.functions import round\nrides \\\n  .select(\"distance\", round(rides.distance / 1609.344, 2)\n  .alias(\"distance_in_miles\")) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07109810-3007-4e17-988d-b88c1708a8db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+-----------------+\n|distance|distance_in_miles|\n+--------+-----------------+\n|   10123|             6.29|\n|   16043|             9.97|\n|    9362|             5.82|\n|    9060|             5.63|\n|    5076|             3.15|\n+--------+-----------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----------------+\ndistance|distance_in_miles|\n+--------+-----------------+\n   10123|             6.29|\n   16043|             9.97|\n    9362|             5.82|\n    9060|             5.63|\n    5076|             3.15|\n+--------+-----------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# To add a new column use the `withColumn` method with a new column name\nrides \\\n  .select([\"id\", \"driver_id\", \"rider_id\", \"date_time\", \"distance\"]) \\\n  .withColumn(\"distance_in_miles\", round(rides.distance / 1609.344, 2)) \\\n  .show(1) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5aaacf41-496f-43be-8c11-c86ee56063ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---+------------+------------+----------------+--------+-----------------+\n| id|   driver_id|    rider_id|       date_time|distance|distance_in_miles|\n+---+------------+------------+----------------+--------+-----------------+\n|  1|220200000214|220200000084|2017-02-01 00:14|   10123|             6.29|\n+---+------------+------------+----------------+--------+-----------------+\nonly showing top 1 row\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------------+------------+----------------+--------+-----------------+\n id|   driver_id|    rider_id|       date_time|distance|distance_in_miles|\n+---+------------+------------+----------------+--------+-----------------+\n  1|220200000214|220200000084|2017-02-01 00:14|   10123|             6.29|\n+---+------------+------------+----------------+--------+-----------------+\nonly showing top 1 row\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# To replace the existing column use the `withColumn` method with the existing column name\nrides \\\n  .select(\"id\", \"driver_id\", \"rider_id\", \"date_time\", \"distance\") \\\n  .withColumn(\"distance\", round(rides.distance / 1609.344, 2)) \\\n  .show(1) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0a30cb6-42a3-4a3b-9494-5beddfc28dfa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---+------------+------------+----------------+--------+\n| id|   driver_id|    rider_id|       date_time|distance|\n+---+------------+------------+----------------+--------+\n|  1|220200000214|220200000084|2017-02-01 00:14|    6.29|\n+---+------------+------------+----------------+--------+\nonly showing top 1 row\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------------+------------+----------------+--------+\n id|   driver_id|    rider_id|       date_time|distance|\n+---+------------+------------+----------------+--------+\n  1|220200000214|220200000084|2017-02-01 00:14|    6.29|\n+---+------------+------------+----------------+--------+\nonly showing top 1 row\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 2: Converting the ride id from an integer to a string\n\n**Note:** We use the [printf format string](https://en.wikipedia.org/wiki/Printf_format_string) \"%010d\" to achieve the desired format (a 10 digit decimal)\n\n![printf](https://cis442f-open-data.s3.amazonaws.com/pictures/printf.png \"printf\")\n\n**Printf format string** refers to a control parameter used by a class of functions in the input/output libraries of C and many other programming languages. The string is written in a simple template language: characters are usually copied literally into the function's output, but format specifiers, which start with a % character, indicate the location and method to translate a piece of data (such as a number) to characters. Many languages other than C copy the printf format string syntax closely or exactly in their own I/O functions.\n\nIn production contexts we should really read data it into the DataFrame in the way we want it if at all possible."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d17873e-4fb5-4fb6-8c50-32c085770a3e"}}},{"cell_type":"code","source":["# Convert the `id` key to a left-zero-padded string:\nfrom pyspark.sql.functions import format_string\nrides.select(\"id\", format_string(\"%010d\", \"id\").alias(\"id_fixed\")).show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d50b56cc-135c-4272-a417-29237737c7ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---+----------+\n| id|  id_fixed|\n+---+----------+\n|  1|0000000001|\n|  2|0000000002|\n|  3|0000000003|\n|  4|0000000004|\n|  5|0000000005|\n+---+----------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+\n id|  id_fixed|\n+---+----------+\n  1|0000000001|\n  2|0000000002|\n  3|0000000003|\n  4|0000000004|\n  5|0000000005|\n+---+----------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Working with string columns\n\n#### Example 3: Normalizing the sex column in the riders table\n\nTrim whitespace and convert rider sex to uppercase ( a common preprocessing step)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15aa8d2a-a183-4496-9d66-202221ae043a"}}},{"cell_type":"code","source":["# Trim whitespace and convert rider sex to uppercase\nfrom pyspark.sql.functions import trim, upper\nriders \\\n  .select(\"sex\", upper(trim(riders.sex)).alias(\"gender\")) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9712a7a-9468-45ea-a944-a6ed38cb17cd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------+------+\n|   sex|gender|\n+------+------+\n|female|FEMALE|\n|  male|  MALE|\n|  male|  MALE|\n|female|FEMALE|\n|  male|  MALE|\n+------+------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+------+\n   sex|gender|\n+------+------+\nfemale|FEMALE|\n  male|  MALE|\n  male|  MALE|\nfemale|FEMALE|\n  male|  MALE|\n+------+------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 4: Extracting Census Block Group from the rider's Census Block\n\nThe [Census Block Group](https://en.wikipedia.org/wiki/Census_block_group) is the first 12 digits of the [Census Block](https://en.wikipedia.org/wiki/Census_block)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9eedef01-7eb5-47fe-8924-d3d16fbceeab"}}},{"cell_type":"code","source":["# Extracting Census Block Group from the rider's Census Block\nfrom pyspark.sql.functions import substring\nriders \\\n  .select(\"home_block\", substring(\"home_block\", 1, 12).alias(\"home_block_group\")) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6af0ce3e-8d55-47cd-b827-f84367c011b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------+----------------+\n|     home_block|home_block_group|\n+---------------+----------------+\n|380170405002188|    380170405002|\n|380170405002360|    380170405002|\n|380170103071039|    380170103071|\n|380170102013021|    380170102013|\n|380170009032023|    380170009032|\n+---------------+----------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+----------------+\n     home_block|home_block_group|\n+---------------+----------------+\n380170405002188|    380170405002|\n380170405002360|    380170405002|\n380170103071039|    380170103071|\n380170102013021|    380170102013|\n380170009032023|    380170009032|\n+---------------+----------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 5: Regular Expressions\n\nUse a regular expression to extract the Census Block Group. \n\n**Note:**\n- We `cast` the home_block column to `string` since regex functions expect a string\n- The regex expresson show that two groups of characters could be catpured `(/d{12})` and `(.*)`.\n- The third parameter in the regexp_extract function (1) indicates that this first group should be extracted"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf39402b-e223-45a0-b65f-933acff337e7"}}},{"cell_type":"code","source":["# Use a regular expression to extract the Census Block Group\nfrom pyspark.sql.functions import regexp_extract\nriders \\\n  .select(\"home_block\", regexp_extract(riders.home_block.cast(\"string\"), \"^(\\d{12})(.*)\", 1).alias(\"home_block_group\")) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56ced413-5c24-47ea-9956-3b6a2fc21932"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------+----------------+\n|     home_block|home_block_group|\n+---------------+----------------+\n|380170405002188|    380170405002|\n|380170405002360|    380170405002|\n|380170103071039|    380170103071|\n|380170102013021|    380170102013|\n|380170009032023|    380170009032|\n+---------------+----------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+----------------+\n     home_block|home_block_group|\n+---------------+----------------+\n380170405002188|    380170405002|\n380170405002360|    380170405002|\n380170103071039|    380170103071|\n380170102013021|    380170102013|\n380170009032023|    380170009032|\n+---------------+----------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# This version extracts the second group from the regex expression just to \n# illustrate the operation of regexp_extract\nfrom pyspark.sql.functions import regexp_extract\nriders \\\n  .select(\"home_block\", regexp_extract(riders.home_block.cast(\"string\"), \"^(\\d{12})(.*)\", 2).alias(\"remaining_part\")) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc3e782e-c6f8-4a2b-ada5-acdd8e3885f7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------+--------------+\n|     home_block|remaining_part|\n+---------------+--------------+\n|380170405002188|           188|\n|380170405002360|           360|\n|380170103071039|           039|\n|380170102013021|           021|\n|380170009032023|           023|\n+---------------+--------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+--------------+\n     home_block|remaining_part|\n+---------------+--------------+\n380170405002188|           188|\n380170405002360|           360|\n380170103071039|           039|\n380170102013021|           021|\n380170009032023|           023|\n+---------------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Working with datetime columns\n\n#### Example 6: Fix birth date\n\n**Note:** \n- We could use the `withColumn` method as above to add a new column or replace an existing one\n- Explict specification of the data format uses [Java SimpleDateFormat](https://docs.oracle.com/javase/tutorial/i18n/format/simpleDateFormat.html). \n- These paragraphs introduce some of the functions available for working with date and timestamp columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae2e5223-a736-4c11-aae5-85018abb6d2d"}}},{"cell_type":"code","source":["# Fix birth date\nfrom pyspark.sql.functions import to_date\nriders \\\n  .select(\"birth_date\", to_date(\"birth_date\").alias(\"birth_date_fixed\")) \\\n  .show(5) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6162343-c1c8-4750-825c-323a1076bf91"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+----------------+\n|birth_date|birth_date_fixed|\n+----------+----------------+\n|1962-03-18|      1962-03-18|\n|1981-10-06|      1981-10-06|\n|1994-12-05|      1994-12-05|\n|1970-05-31|      1970-05-31|\n|1962-12-12|      1962-12-12|\n+----------+----------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------------+\nbirth_date|birth_date_fixed|\n+----------+----------------+\n1962-03-18|      1962-03-18|\n1981-10-06|      1981-10-06|\n1994-12-05|      1994-12-05|\n1970-05-31|      1970-05-31|\n1962-12-12|      1962-12-12|\n+----------+----------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Fix birth date using explict specification of the date format\nfrom pyspark.sql.functions import to_date\nriders \\\n  .select(\"birth_date\", to_date(\"birth_date\", \"yyyy-MM-dd\").alias(\"birth_date_fixed\")) \\\n  .show(5) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c649404c-bcb8-406f-985c-cd80bdb869ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+----------------+\n|birth_date|birth_date_fixed|\n+----------+----------------+\n|1962-03-18|      1962-03-18|\n|1981-10-06|      1981-10-06|\n|1994-12-05|      1994-12-05|\n|1970-05-31|      1970-05-31|\n|1962-12-12|      1962-12-12|\n+----------+----------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------------+\nbirth_date|birth_date_fixed|\n+----------+----------------+\n1962-03-18|      1962-03-18|\n1981-10-06|      1981-10-06|\n1994-12-05|      1994-12-05|\n1970-05-31|      1970-05-31|\n1962-12-12|      1962-12-12|\n+----------+----------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 7: Compute rider age\n\n**Note:** Spark implicitly casts `birth_date` or `today` as necessary.  It is\nprobably safer to explicitly cast one of these columns before computing the\nnumber of months between."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0a638fd-d9f9-4a63-a08c-48cf1baee4c0"}}},{"cell_type":"code","source":["# Compute rider age\nfrom pyspark.sql.functions import to_date, current_date, months_between, floor, to_timestamp\nriders \\\n  .select(\"birth_date\", current_date().alias(\"today\")) \\\n  .withColumn(\"age\", floor(months_between(\"today\", \"birth_date\") / 12)) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91780c4d-292e-43fb-818d-accef7211abc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+----------+---+\n|birth_date|     today|age|\n+----------+----------+---+\n|1962-03-18|2021-06-10| 59|\n|1981-10-06|2021-06-10| 39|\n|1994-12-05|2021-06-10| 26|\n|1970-05-31|2021-06-10| 51|\n|1962-12-12|2021-06-10| 58|\n+----------+----------+---+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------+---+\nbirth_date|     today|age|\n+----------+----------+---+\n1962-03-18|2021-06-10| 59|\n1981-10-06|2021-06-10| 39|\n1994-12-05|2021-06-10| 26|\n1970-05-31|2021-06-10| 51|\n1962-12-12|2021-06-10| 58|\n+----------+----------+---+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Compute rider age making sure that birth_data has been converted to DateType()\nfrom pyspark.sql.functions import to_date, current_date, months_between, floor\nriders \\\n  .select(to_date(\"birth_date\", \"yyyy-MM-dd\").alias(\"birth_date_fixed\"), current_date().alias(\"today\")) \\\n  .withColumn(\"age\", floor(months_between(\"today\", \"birth_date_fixed\") / 12)) \\\n  .show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a15c6ad7-9852-45e3-bfe0-e1b4802cff94"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------+----------+---+\n|birth_date_fixed|     today|age|\n+----------------+----------+---+\n|      1962-03-18|2021-06-10| 59|\n|      1981-10-06|2021-06-10| 39|\n|      1994-12-05|2021-06-10| 26|\n|      1970-05-31|2021-06-10| 51|\n|      1962-12-12|2021-06-10| 58|\n+----------------+----------+---+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------+----------+---+\nbirth_date_fixed|     today|age|\n+----------------+----------+---+\n      1962-03-18|2021-06-10| 59|\n      1981-10-06|2021-06-10| 39|\n      1994-12-05|2021-06-10| 26|\n      1970-05-31|2021-06-10| 51|\n      1962-12-12|2021-06-10| 58|\n+----------------+----------+---+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 8: Fix ride date and time\n\nNote that explict specification of the data and time format uses [Java SimpleDateFormat](https://docs.oracle.com/javase/tutorial/i18n/format/simpleDateFormat.html)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd9181a6-8907-4333-9d95-4e2c93f77b8b"}}},{"cell_type":"code","source":["# Fix ride date and time\nrides \\\n  .select(\"date_time\", rides.date_time.cast(\"timestamp\").alias(\"date_time_fixed\")) \\\n  .show(5, truncate=False)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8873e91e-dd8e-4910-816a-ef55f28e4b74"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------+-------------------+\n|date_time       |date_time_fixed    |\n+----------------+-------------------+\n|2017-02-01 00:14|2017-02-01 00:14:00|\n|2017-02-01 00:36|2017-02-01 00:36:00|\n|2017-02-01 02:26|2017-02-01 02:26:00|\n|2017-02-01 03:00|2017-02-01 03:00:00|\n|2017-02-01 03:49|2017-02-01 03:49:00|\n+----------------+-------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------+-------------------+\ndate_time       |date_time_fixed    |\n+----------------+-------------------+\n2017-02-01 00:14|2017-02-01 00:14:00|\n2017-02-01 00:36|2017-02-01 00:36:00|\n2017-02-01 02:26|2017-02-01 02:26:00|\n2017-02-01 03:00|2017-02-01 03:00:00|\n2017-02-01 03:49|2017-02-01 03:49:00|\n+----------------+-------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Fix ride date and time (with explict date time format)\nrides \\\n  .select(\"date_time\", to_timestamp(\"date_time\", 'yyyy-MM-dd HH:mm').alias(\"date_time_fixed\")) \\\n  .show(5, truncate=False) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8587ad0-5052-4e1f-802b-88a637a576b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------+-------------------+\n|date_time       |date_time_fixed    |\n+----------------+-------------------+\n|2017-02-01 00:14|2017-02-01 00:14:00|\n|2017-02-01 00:36|2017-02-01 00:36:00|\n|2017-02-01 02:26|2017-02-01 02:26:00|\n|2017-02-01 03:00|2017-02-01 03:00:00|\n|2017-02-01 03:49|2017-02-01 03:49:00|\n+----------------+-------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------+-------------------+\ndate_time       |date_time_fixed    |\n+----------------+-------------------+\n2017-02-01 00:14|2017-02-01 00:14:00|\n2017-02-01 00:36|2017-02-01 00:36:00|\n2017-02-01 02:26|2017-02-01 02:26:00|\n2017-02-01 03:00|2017-02-01 03:00:00|\n2017-02-01 03:49|2017-02-01 03:49:00|\n+----------------+-------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 9: Multiple Boolean Column expressions\n\n**Note:** \n- The OR operator is `|`\n- The AND operator is `&`\n- How the difference in how nulls are treated in the computation:\n-- true & null = null\n-- false & null = false\n-- true | null = true\n-- false | null = null\n- Spark is quite sensitive to parentheses. Parentheses are needed if the two _Boolean Column Expressions_ are used directly in the select statement\n- The automatically generated column names reflect the logic that generated them"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"229f357f-fc06-4042-9aba-64d92fd2ca96"}}},{"cell_type":"code","source":["# Predefine the Boolean Column expressions (these are both column objects)\nstudentFilter = riders.student == 1\nmaleFilter = riders[\"sex\"] == \"male\"\n\nprint (\"The type of maleFilter is: \" + str(type(maleFilter)))\n\n# Combine using the AND operator\nriders.select(\"student\", \"sex\", studentFilter & maleFilter).show(15) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9757c0ce-b94d-439e-9668-37cd177ff3e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">The type of maleFilter is: &lt;class &#39;pyspark.sql.column.Column&#39;&gt;\n+-------+------+--------------------------------+\n|student|   sex|((student = 1) AND (sex = male))|\n+-------+------+--------------------------------+\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      1|  null|                            null|\n|      1|  male|                            true|\n|      1|  male|                            true|\n|      0|  male|                           false|\n|      0|  male|                           false|\n+-------+------+--------------------------------+\nonly showing top 15 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The type of maleFilter is: &lt;class &#39;pyspark.sql.column.Column&#39;&gt;\n+-------+------+--------------------------------+\nstudent|   sex|((student = 1) AND (sex = male))|\n+-------+------+--------------------------------+\n      0|female|                           false|\n      0|  male|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      1|  null|                            null|\n      1|  male|                            true|\n      1|  male|                            true|\n      0|  male|                           false|\n      0|  male|                           false|\n+-------+------+--------------------------------+\nonly showing top 15 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Combine using the OR operator\nriders.select(\"student\", \"sex\", studentFilter | maleFilter).show(15)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c16721cd-35b2-46bb-8d87-4c34afe4636e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+-------------------------------+\n|student|   sex|((student = 1) OR (sex = male))|\n+-------+------+-------------------------------+\n|      0|female|                          false|\n|      0|  male|                           true|\n|      0|  male|                           true|\n|      0|female|                          false|\n|      0|  male|                           true|\n|      0|female|                          false|\n|      0|  male|                           true|\n|      0|female|                          false|\n|      0|  male|                           true|\n|      0|female|                          false|\n|      1|  null|                           true|\n|      1|  male|                           true|\n|      1|  male|                           true|\n|      0|  male|                           true|\n|      0|  male|                           true|\n+-------+------+-------------------------------+\nonly showing top 15 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+-------------------------------+\nstudent|   sex|((student = 1) OR (sex = male))|\n+-------+------+-------------------------------+\n      0|female|                          false|\n      0|  male|                           true|\n      0|  male|                           true|\n      0|female|                          false|\n      0|  male|                           true|\n      0|female|                          false|\n      0|  male|                           true|\n      0|female|                          false|\n      0|  male|                           true|\n      0|female|                          false|\n      1|  null|                           true|\n      1|  male|                           true|\n      1|  male|                           true|\n      0|  male|                           true|\n      0|  male|                           true|\n+-------+------+-------------------------------+\nonly showing top 15 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Check the type of the Boolean Column Expression\ntype (riders.student == 1)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f94565fc-24fa-4dfb-81b0-ddc49f380c85"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[18]: pyspark.sql.column.Column</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: pyspark.sql.column.Column</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Combine using the AND operator with Boolean Column Expressions directly in the select method\nriders.select(\"student\", \"sex\", (riders.student == 1) & (riders[\"sex\"] == \"male\")).show(15) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d36fb50c-f1eb-49b8-bd3b-18cecf70ea4a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+------+--------------------------------+\n|student|   sex|((student = 1) AND (sex = male))|\n+-------+------+--------------------------------+\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      0|  male|                           false|\n|      0|female|                           false|\n|      1|  null|                            null|\n|      1|  male|                            true|\n|      1|  male|                            true|\n|      0|  male|                           false|\n|      0|  male|                           false|\n+-------+------+--------------------------------+\nonly showing top 15 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------+--------------------------------+\nstudent|   sex|((student = 1) AND (sex = male))|\n+-------+------+--------------------------------+\n      0|female|                           false|\n      0|  male|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      0|  male|                           false|\n      0|female|                           false|\n      1|  null|                            null|\n      1|  male|                            true|\n      1|  male|                            true|\n      0|  male|                           false|\n      0|  male|                           false|\n+-------+------+--------------------------------+\nonly showing top 15 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Example 10: Using multiple boolean expressions in a filter\n\nNote: If you want to specify multiple AND fitlers, you can just chain them sequentially."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81485003-aab8-4b5d-b415-95f709dacdae"}}},{"cell_type":"code","source":["# Using multiple boolean expressions in a filter\nriders.filter(maleFilter & studentFilter).select(\"student\", \"sex\").show(5) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3d627b8-72d3-4f1d-97cf-fa21b996f110"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+----+\n|student| sex|\n+-------+----+\n|      1|male|\n|      1|male|\n|      1|male|\n|      1|male|\n|      1|male|\n+-------+----+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----+\nstudent| sex|\n+-------+----+\n      1|male|\n      1|male|\n      1|male|\n      1|male|\n      1|male|\n+-------+----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Using multiple boolean expressions in a filter is equivalent to this sequential chaining of filters\nriders.filter(maleFilter).filter(studentFilter).select(\"student\", \"sex\").show(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c674419e-355e-4123-b9d2-30b046808d9c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+----+\n|student| sex|\n+-------+----+\n|      1|male|\n|      1|male|\n|      1|male|\n|      1|male|\n|      1|male|\n+-------+----+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----+\nstudent| sex|\n+-------+----+\n      1|male|\n      1|male|\n      1|male|\n      1|male|\n      1|male|\n+-------+----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Hands On\n\n![Hands-on](https://cis442f-open-data.s3.amazonaws.com/pictures/hands.png \"Hands-on\")\n\n\n#### Exercises\n\n(1) Convert the `rides.driver_id` column to a string column.\n\n(2) Extract the year from the `rides.date_time` column (hint: you can use the `year` function)\n\n(3) Convert `rides.duration` from seconds to minutes.\n\n(4) Convert the `rides.cancelled` column to a boolean column.\n\n(5) Convert the `rides.star_rating` column to a double column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54f95d15-0057-4b9c-ab08-f2e18eda13c6"}}},{"cell_type":"code","source":["# Submit your solution in the following format\n\nrides = spark.read.csv(\"/mnt/cis442f-data/duocar/raw/rides/\", header=True, inferSchema=True)\nfrom pyspark.sql.functions import format_string, year, col, round\nrides = rides\\\n  .withColumn(XXXXXXXXXX)\\\n  .withColumn(XXXXXXXXXXXXXX)\\\n  .withColumn(XXXXXXXXXXXXXX)\\\n  .withColumn(XXXXXXXXXXXXXXXX)\\\n  .withColumn(XXXXXXXXXXXXXXXX)\n\nrides.show(5)\nrides.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c4ff62b-34d6-4178-b1b7-09fc4ef370fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1925831442517417&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> format_string<span class=\"ansi-blue-fg\">,</span> year<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">,</span> round\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> rides <span class=\"ansi-blue-fg\">=</span> rides<span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>XXXXXXXXXX<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>   <span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>XXXXXXXXXXXXXX<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>   <span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>XXXXXXXXXXXXXX<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;XXXXXXXXXX&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;XXXXXXXXXX&#39; is not defined","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1925831442517417&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> format_string<span class=\"ansi-blue-fg\">,</span> year<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">,</span> round\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> rides <span class=\"ansi-blue-fg\">=</span> rides<span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>XXXXXXXXXX<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>   <span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>XXXXXXXXXXXXXX<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>   <span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>XXXXXXXXXXXXXX<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;XXXXXXXXXX&#39; is not defined</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**References**\n\n[DataFrame class](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame)\n\n[Column class](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.html#pyspark.sql.Column)\n\n[pyspark.sql.functions module](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions)\n\nAll of the above are part of the [Python Spark SQL API Reference](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html) which you should get to know your way around"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f5aa742-abb0-4d9d-826c-cd86b85181c8"}}},{"cell_type":"markdown","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1d96f57-9e6e-4dc4-9bb5-700efe08a978"}}}],"metadata":{"kernelspec":{"display_name":"Spark 2.0.0 - Scala 2.11","language":"scala","name":"spark2-scala"},"language_info":{"mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","codemirror_mode":"text/x-scala","version":"2.11.8","file_extension":".scala"},"application/vnd.databricks.v1+notebook":{"notebookName":"08b. Transforming DataFrame Columns","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3306189708976658}},"nbformat":4,"nbformat_minor":0}
