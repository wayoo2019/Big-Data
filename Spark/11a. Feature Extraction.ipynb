{"cells":[{"cell_type":"markdown","source":["### Extracting, transforming, and selecting features (for class)\n\nIn this notebook we demonstrate some of the functionality available in Spark MLlib to extract, transform, and select features for machine learning.  In particular, we generate features from the ride review text that can be used to predict the ride rating.  We cover a small subset of the available transformations here but will cover additional transformations in subsequent modules. This notebook is based on material supplied by Cloudera under their Cloudera Academic Partner program and *Spark: The Definitive Guide* book by Bill Chambers and Matei Zaharia. \n\nTopics: Extracting and transforming features\n- Tokenizer\n- RegexTokenizer\n- StopWordsRemover\n- CountVectorizer (convert documents of words to numbers)\n- ChiSqSelector\n\nYou can find details of all of these *Transformers*, *Estimators* along with their methods and attributes in the [Spark MLlib API Reference](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html) and a more general guide to their use in the [Machine Learning Library (MLlib) Guide](https://spark.apache.org/docs/latest/ml-guide.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe91c26f-50f0-4cf0-81b1-bfa23a55ff6a"}}},{"cell_type":"code","source":["# Read the ride review data\nreviews = spark.read.parquet(\"/mnt/cis442f-data/duocar/clean/ride_reviews/\")\n\n# Read the ride data\nrides = spark.read.parquet(\"/mnt/cis442f-data/duocar/clean/rides/\")\n\n# We only want the rides with reviews, so left outer join `reviews` and `rides`\njoined = reviews.join(rides, reviews.ride_id == rides.id, \"left_outer\")\n\n# Select the subset of columns in which we are interested\nreviews_with_ratings = joined.select(\"ride_id\", \"review\", \"star_rating\")\n\n# This small sample of the resulting DataFrame indicates that there may well\n# be a relationship between the review and the rating (eyeball algorithm)\nfor item in reviews_with_ratings.head(5):\n    print (item)    "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4a438c6-df62-4a09-9498-e3bc285eab21"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Row(ride_id=&#39;0000000009&#39;, review=&#39;Dale is extremely cordial.&#39;, star_rating=5)\nRow(ride_id=&#39;0000000037&#39;, review=&#39;Very junky car.&#39;, star_rating=2)\nRow(ride_id=&#39;0000000071&#39;, review=&#39;most awful stench of all time! throw away your air freshener!&#39;, star_rating=2)\nRow(ride_id=&#39;0000000083&#39;, review=&#39;No trouble of note.&#39;, star_rating=3)\nRow(ride_id=&#39;0000000086&#39;, review=&#39;The driver drove so well!!&#39;, star_rating=5)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Row(ride_id=&#39;0000000009&#39;, review=&#39;Dale is extremely cordial.&#39;, star_rating=5)\nRow(ride_id=&#39;0000000037&#39;, review=&#39;Very junky car.&#39;, star_rating=2)\nRow(ride_id=&#39;0000000071&#39;, review=&#39;most awful stench of all time! throw away your air freshener!&#39;, star_rating=2)\nRow(ride_id=&#39;0000000083&#39;, review=&#39;No trouble of note.&#39;, star_rating=3)\nRow(ride_id=&#39;0000000086&#39;, review=&#39;The driver drove so well!!&#39;, star_rating=5)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Extracting and transforming features\n\nThe ride reviews are not in a form amenable to machine learning algorithms. Spark MLlib provides a number of feature extractors and feature transformers to preprocess the ride reviews into a form appropriate for modeling. We start with _tokenizing_ the reviews data using `Tokenizer`.\n\n**Note:** \n- `Tokenizer` is a *Transformer* since it takes a DataFrame as input and returns a DataFrame as output via its `transform` method.\n- The Data Type returned is an *arrary*, one of Spark's complex types\n- Punctuation is not being handled properly.  I will ask you to use the `RegexTokenizer` class to split on characters other than whitespace for one of the hands on exercises."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"565eee12-102b-4317-8789-e1a4802e47bb"}}},{"cell_type":"code","source":["# Use the 'Tokenizer' class to tokenize the reviews\nfrom pyspark.ml.feature import Tokenizer\ntokenizer = Tokenizer(inputCol=\"review\", outputCol=\"words\")\ntokenized = tokenizer.transform(reviews_with_ratings)\n\n# tokenized.show(5,False)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3de8b75-b82e-44b1-9dee-96e7abb90b56"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Examine a sample of tokens\nfor item in tokenized.select(\"review\", \"words\").head(5):\n    print (item[0], item[1])\n    # print (\"\\n\")"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28d019f8-bd31-40ac-aecf-7a5f83f7c0bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Dale is extremely cordial. [&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial.&#39;]\nVery junky car. [&#39;very&#39;, &#39;junky&#39;, &#39;car.&#39;]\nmost awful stench of all time! throw away your air freshener! [&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener!&#39;]\nNo trouble of note. [&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note.&#39;]\nThe driver drove so well!! [&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well!!&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Dale is extremely cordial. [&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial.&#39;]\nVery junky car. [&#39;very&#39;, &#39;junky&#39;, &#39;car.&#39;]\nmost awful stench of all time! throw away your air freshener! [&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener!&#39;]\nNo trouble of note. [&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note.&#39;]\nThe driver drove so well!! [&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well!!&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["`CountVectorizer` and `CountVectorizerModel` aim to help convert a collection of text documents (the rows of the `words` column in our case) to vectors of token counts. When an a-priori dictionary is not available, `CountVectorizer` can be used as an Estimator to extract the vocabulary, and generates a `CountVectorizerModel`. The model produces sparse representations for the documents over the vocabulary, which can then be passed to other algorithms.\n\nDuring the fitting process, `CountVectorizer` will select the top `vocabSize` words ordered by term frequency across the corpus. An optional parameter `minDF` also affects the fitting process by specifying the minimum number (or fraction if < 1.0) of documents a term must appear in to be included in the vocabulary. Another optional `binary` toggle parameter controls the output vector. If set to true all nonzero counts are set to 1. This is especially useful for discrete probabilistic models that model binary, rather than integer, counts. [Source of this description](https://spark.apache.org/docs/latest/ml-features.html#countvectorizer)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f83bc992-f93e-4516-950d-4e6476b34a98"}}},{"cell_type":"code","source":["# Next we use the `CountVectorizer` class to compute the term frequency\n# Will produce top ten most frequent words are a vocabulary\n\nfrom pyspark.ml.feature import CountVectorizer\nvectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"words_vectorized\", vocabSize=10)\nvectorizer_model = vectorizer.fit(tokenized)\nvectorized = vectorizer_model.transform(tokenized)\n# vectorized.select(\"words\", \"words_vectorized\").head(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f357f8b3-97b8-4666-949e-c5a898c05998"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Examine vectors\nfor item in vectorized.select(\"words\", \"words_vectorized\").head(5):\n    print (item[0], item[1])"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21d2a016-2f95-4f55-bec6-5480a32f4396"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] (10,[],[])\n[&#39;very&#39;, &#39;junky&#39;, &#39;car.&#39;] (10,[],[])\n[&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener!&#39;] (10,[5],[1.0])\n[&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note.&#39;] (10,[],[])\n[&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well!!&#39;] (10,[0,2],[1.0,1.0])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] (10,[],[])\n[&#39;very&#39;, &#39;junky&#39;, &#39;car.&#39;] (10,[],[])\n[&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener!&#39;] (10,[5],[1.0])\n[&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note.&#39;] (10,[],[])\n[&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well!!&#39;] (10,[0,2],[1.0,1.0])\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Note:**\n- `CountVectorizer` is an `Estimator` since it takes a DataFrame as input and returns a `Transformer` as output via its `fit` method.  In this case, the resulting transformer is an instance of the  `CountVectorizerModel` class.\n- The resulting word vector is stored in sparse format. First number is the `vocabSize`, the dictionary key is the index of the word in the `vocabulary` (see below) and the dictionary value is the frequency of the word in the document (the review data for a ride in this example)\n- Our limited vocabulary (see below) includes a number of common words such as \"the\" that we do not expect to be predictive\n\n\nThe [HashingTF](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.HashingTF.html#pyspark.ml.feature.HashingTF) class is an alternative for computing the term frequency which we can try in the Hands On exercises"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fda8c628-7377-4eb0-9c4f-ce338420dddf"}}},{"cell_type":"code","source":["# Examine vocabulary identified by CountVectorizer\nlist(enumerate(vectorizer_model.vocabulary)) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"313b0e4d-af56-453c-bb8d-6568340a2172"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: [(0, &#39;the&#39;),\n (1, &#39;to&#39;),\n (2, &#39;driver&#39;),\n (3, &#39;ride&#39;),\n (4, &#39;was&#39;),\n (5, &#39;air&#39;),\n (6, &#39;i&#39;),\n (7, &#39;and&#39;),\n (8, &#39;a&#39;),\n (9, &#39;this&#39;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: [(0, &#39;the&#39;),\n (1, &#39;to&#39;),\n (2, &#39;driver&#39;),\n (3, &#39;ride&#39;),\n (4, &#39;was&#39;),\n (5, &#39;air&#39;),\n (6, &#39;i&#39;),\n (7, &#39;and&#39;),\n (8, &#39;a&#39;),\n (9, &#39;this&#39;)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Spark MLlib provides a transformer to remove these so-called \"stop words\".  Use the `StopWordsRemover`\n class to remove common words"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3625cd59-38dc-4411-bc58-5775fd7c2ca7"}}},{"cell_type":"code","source":["# Use the `StopWordsRemover` class to remove common words\n\nfrom pyspark.ml.feature import StopWordsRemover\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_removed\")\nremoved = remover.transform(tokenized)\n\n# Show Stopwords\nremover.getStopWords() "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a670e0e4-1839-4671-8129-6584b79f28a3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[8]: [&#39;i&#39;,\n &#39;me&#39;,\n &#39;my&#39;,\n &#39;myself&#39;,\n &#39;we&#39;,\n &#39;our&#39;,\n &#39;ours&#39;,\n &#39;ourselves&#39;,\n &#39;you&#39;,\n &#39;your&#39;,\n &#39;yours&#39;,\n &#39;yourself&#39;,\n &#39;yourselves&#39;,\n &#39;he&#39;,\n &#39;him&#39;,\n &#39;his&#39;,\n &#39;himself&#39;,\n &#39;she&#39;,\n &#39;her&#39;,\n &#39;hers&#39;,\n &#39;herself&#39;,\n &#39;it&#39;,\n &#39;its&#39;,\n &#39;itself&#39;,\n &#39;they&#39;,\n &#39;them&#39;,\n &#39;their&#39;,\n &#39;theirs&#39;,\n &#39;themselves&#39;,\n &#39;what&#39;,\n &#39;which&#39;,\n &#39;who&#39;,\n &#39;whom&#39;,\n &#39;this&#39;,\n &#39;that&#39;,\n &#39;these&#39;,\n &#39;those&#39;,\n &#39;am&#39;,\n &#39;is&#39;,\n &#39;are&#39;,\n &#39;was&#39;,\n &#39;were&#39;,\n &#39;be&#39;,\n &#39;been&#39;,\n &#39;being&#39;,\n &#39;have&#39;,\n &#39;has&#39;,\n &#39;had&#39;,\n &#39;having&#39;,\n &#39;do&#39;,\n &#39;does&#39;,\n &#39;did&#39;,\n &#39;doing&#39;,\n &#39;a&#39;,\n &#39;an&#39;,\n &#39;the&#39;,\n &#39;and&#39;,\n &#39;but&#39;,\n &#39;if&#39;,\n &#39;or&#39;,\n &#39;because&#39;,\n &#39;as&#39;,\n &#39;until&#39;,\n &#39;while&#39;,\n &#39;of&#39;,\n &#39;at&#39;,\n &#39;by&#39;,\n &#39;for&#39;,\n &#39;with&#39;,\n &#39;about&#39;,\n &#39;against&#39;,\n &#39;between&#39;,\n &#39;into&#39;,\n &#39;through&#39;,\n &#39;during&#39;,\n &#39;before&#39;,\n &#39;after&#39;,\n &#39;above&#39;,\n &#39;below&#39;,\n &#39;to&#39;,\n &#39;from&#39;,\n &#39;up&#39;,\n &#39;down&#39;,\n &#39;in&#39;,\n &#39;out&#39;,\n &#39;on&#39;,\n &#39;off&#39;,\n &#39;over&#39;,\n &#39;under&#39;,\n &#39;again&#39;,\n &#39;further&#39;,\n &#39;then&#39;,\n &#39;once&#39;,\n &#39;here&#39;,\n &#39;there&#39;,\n &#39;when&#39;,\n &#39;where&#39;,\n &#39;why&#39;,\n &#39;how&#39;,\n &#39;all&#39;,\n &#39;any&#39;,\n &#39;both&#39;,\n &#39;each&#39;,\n &#39;few&#39;,\n &#39;more&#39;,\n &#39;most&#39;,\n &#39;other&#39;,\n &#39;some&#39;,\n &#39;such&#39;,\n &#39;no&#39;,\n &#39;nor&#39;,\n &#39;not&#39;,\n &#39;only&#39;,\n &#39;own&#39;,\n &#39;same&#39;,\n &#39;so&#39;,\n &#39;than&#39;,\n &#39;too&#39;,\n &#39;very&#39;,\n &#39;s&#39;,\n &#39;t&#39;,\n &#39;can&#39;,\n &#39;will&#39;,\n &#39;just&#39;,\n &#39;don&#39;,\n &#39;should&#39;,\n &#39;now&#39;,\n &#34;i&#39;ll&#34;,\n &#34;you&#39;ll&#34;,\n &#34;he&#39;ll&#34;,\n &#34;she&#39;ll&#34;,\n &#34;we&#39;ll&#34;,\n &#34;they&#39;ll&#34;,\n &#34;i&#39;d&#34;,\n &#34;you&#39;d&#34;,\n &#34;he&#39;d&#34;,\n &#34;she&#39;d&#34;,\n &#34;we&#39;d&#34;,\n &#34;they&#39;d&#34;,\n &#34;i&#39;m&#34;,\n &#34;you&#39;re&#34;,\n &#34;he&#39;s&#34;,\n &#34;she&#39;s&#34;,\n &#34;it&#39;s&#34;,\n &#34;we&#39;re&#34;,\n &#34;they&#39;re&#34;,\n &#34;i&#39;ve&#34;,\n &#34;we&#39;ve&#34;,\n &#34;you&#39;ve&#34;,\n &#34;they&#39;ve&#34;,\n &#34;isn&#39;t&#34;,\n &#34;aren&#39;t&#34;,\n &#34;wasn&#39;t&#34;,\n &#34;weren&#39;t&#34;,\n &#34;haven&#39;t&#34;,\n &#34;hasn&#39;t&#34;,\n &#34;hadn&#39;t&#34;,\n &#34;don&#39;t&#34;,\n &#34;doesn&#39;t&#34;,\n &#34;didn&#39;t&#34;,\n &#34;won&#39;t&#34;,\n &#34;wouldn&#39;t&#34;,\n &#34;shan&#39;t&#34;,\n &#34;shouldn&#39;t&#34;,\n &#34;mustn&#39;t&#34;,\n &#34;can&#39;t&#34;,\n &#34;couldn&#39;t&#34;,\n &#39;cannot&#39;,\n &#39;could&#39;,\n &#34;here&#39;s&#34;,\n &#34;how&#39;s&#34;,\n &#34;let&#39;s&#34;,\n &#39;ought&#39;,\n &#34;that&#39;s&#34;,\n &#34;there&#39;s&#34;,\n &#34;what&#39;s&#34;,\n &#34;when&#39;s&#34;,\n &#34;where&#39;s&#34;,\n &#34;who&#39;s&#34;,\n &#34;why&#39;s&#34;,\n &#39;would&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: [&#39;i&#39;,\n &#39;me&#39;,\n &#39;my&#39;,\n &#39;myself&#39;,\n &#39;we&#39;,\n &#39;our&#39;,\n &#39;ours&#39;,\n &#39;ourselves&#39;,\n &#39;you&#39;,\n &#39;your&#39;,\n &#39;yours&#39;,\n &#39;yourself&#39;,\n &#39;yourselves&#39;,\n &#39;he&#39;,\n &#39;him&#39;,\n &#39;his&#39;,\n &#39;himself&#39;,\n &#39;she&#39;,\n &#39;her&#39;,\n &#39;hers&#39;,\n &#39;herself&#39;,\n &#39;it&#39;,\n &#39;its&#39;,\n &#39;itself&#39;,\n &#39;they&#39;,\n &#39;them&#39;,\n &#39;their&#39;,\n &#39;theirs&#39;,\n &#39;themselves&#39;,\n &#39;what&#39;,\n &#39;which&#39;,\n &#39;who&#39;,\n &#39;whom&#39;,\n &#39;this&#39;,\n &#39;that&#39;,\n &#39;these&#39;,\n &#39;those&#39;,\n &#39;am&#39;,\n &#39;is&#39;,\n &#39;are&#39;,\n &#39;was&#39;,\n &#39;were&#39;,\n &#39;be&#39;,\n &#39;been&#39;,\n &#39;being&#39;,\n &#39;have&#39;,\n &#39;has&#39;,\n &#39;had&#39;,\n &#39;having&#39;,\n &#39;do&#39;,\n &#39;does&#39;,\n &#39;did&#39;,\n &#39;doing&#39;,\n &#39;a&#39;,\n &#39;an&#39;,\n &#39;the&#39;,\n &#39;and&#39;,\n &#39;but&#39;,\n &#39;if&#39;,\n &#39;or&#39;,\n &#39;because&#39;,\n &#39;as&#39;,\n &#39;until&#39;,\n &#39;while&#39;,\n &#39;of&#39;,\n &#39;at&#39;,\n &#39;by&#39;,\n &#39;for&#39;,\n &#39;with&#39;,\n &#39;about&#39;,\n &#39;against&#39;,\n &#39;between&#39;,\n &#39;into&#39;,\n &#39;through&#39;,\n &#39;during&#39;,\n &#39;before&#39;,\n &#39;after&#39;,\n &#39;above&#39;,\n &#39;below&#39;,\n &#39;to&#39;,\n &#39;from&#39;,\n &#39;up&#39;,\n &#39;down&#39;,\n &#39;in&#39;,\n &#39;out&#39;,\n &#39;on&#39;,\n &#39;off&#39;,\n &#39;over&#39;,\n &#39;under&#39;,\n &#39;again&#39;,\n &#39;further&#39;,\n &#39;then&#39;,\n &#39;once&#39;,\n &#39;here&#39;,\n &#39;there&#39;,\n &#39;when&#39;,\n &#39;where&#39;,\n &#39;why&#39;,\n &#39;how&#39;,\n &#39;all&#39;,\n &#39;any&#39;,\n &#39;both&#39;,\n &#39;each&#39;,\n &#39;few&#39;,\n &#39;more&#39;,\n &#39;most&#39;,\n &#39;other&#39;,\n &#39;some&#39;,\n &#39;such&#39;,\n &#39;no&#39;,\n &#39;nor&#39;,\n &#39;not&#39;,\n &#39;only&#39;,\n &#39;own&#39;,\n &#39;same&#39;,\n &#39;so&#39;,\n &#39;than&#39;,\n &#39;too&#39;,\n &#39;very&#39;,\n &#39;s&#39;,\n &#39;t&#39;,\n &#39;can&#39;,\n &#39;will&#39;,\n &#39;just&#39;,\n &#39;don&#39;,\n &#39;should&#39;,\n &#39;now&#39;,\n &#34;i&#39;ll&#34;,\n &#34;you&#39;ll&#34;,\n &#34;he&#39;ll&#34;,\n &#34;she&#39;ll&#34;,\n &#34;we&#39;ll&#34;,\n &#34;they&#39;ll&#34;,\n &#34;i&#39;d&#34;,\n &#34;you&#39;d&#34;,\n &#34;he&#39;d&#34;,\n &#34;she&#39;d&#34;,\n &#34;we&#39;d&#34;,\n &#34;they&#39;d&#34;,\n &#34;i&#39;m&#34;,\n &#34;you&#39;re&#34;,\n &#34;he&#39;s&#34;,\n &#34;she&#39;s&#34;,\n &#34;it&#39;s&#34;,\n &#34;we&#39;re&#34;,\n &#34;they&#39;re&#34;,\n &#34;i&#39;ve&#34;,\n &#34;we&#39;ve&#34;,\n &#34;you&#39;ve&#34;,\n &#34;they&#39;ve&#34;,\n &#34;isn&#39;t&#34;,\n &#34;aren&#39;t&#34;,\n &#34;wasn&#39;t&#34;,\n &#34;weren&#39;t&#34;,\n &#34;haven&#39;t&#34;,\n &#34;hasn&#39;t&#34;,\n &#34;hadn&#39;t&#34;,\n &#34;don&#39;t&#34;,\n &#34;doesn&#39;t&#34;,\n &#34;didn&#39;t&#34;,\n &#34;won&#39;t&#34;,\n &#34;wouldn&#39;t&#34;,\n &#34;shan&#39;t&#34;,\n &#34;shouldn&#39;t&#34;,\n &#34;mustn&#39;t&#34;,\n &#34;can&#39;t&#34;,\n &#34;couldn&#39;t&#34;,\n &#39;cannot&#39;,\n &#39;could&#39;,\n &#34;here&#39;s&#34;,\n &#34;how&#39;s&#34;,\n &#34;let&#39;s&#34;,\n &#39;ought&#39;,\n &#34;that&#39;s&#34;,\n &#34;there&#39;s&#34;,\n &#34;what&#39;s&#34;,\n &#34;when&#39;s&#34;,\n &#34;where&#39;s&#34;,\n &#34;who&#39;s&#34;,\n &#34;why&#39;s&#34;,\n &#39;would&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Compare tokenized text and new column without stop words\nfor item in removed.select(\"words\", \"words_removed\").head(5):\n    print (item[0], item[1]) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"745a5340-ac89-45f9-b4f0-ca1a040a3671"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] [&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial.&#39;]\n[&#39;very&#39;, &#39;junky&#39;, &#39;car.&#39;] [&#39;junky&#39;, &#39;car.&#39;]\n[&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener!&#39;] [&#39;awful&#39;, &#39;stench&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener!&#39;]\n[&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note.&#39;] [&#39;trouble&#39;, &#39;note.&#39;]\n[&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well!!&#39;] [&#39;driver&#39;, &#39;drove&#39;, &#39;well!!&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] [&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial.&#39;]\n[&#39;very&#39;, &#39;junky&#39;, &#39;car.&#39;] [&#39;junky&#39;, &#39;car.&#39;]\n[&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener!&#39;] [&#39;awful&#39;, &#39;stench&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener!&#39;]\n[&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note.&#39;] [&#39;trouble&#39;, &#39;note.&#39;]\n[&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well!!&#39;] [&#39;driver&#39;, &#39;drove&#39;, &#39;well!!&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Recount the words\nvectorizer = CountVectorizer(inputCol=\"words_removed\", outputCol=\"words_vectorized\", vocabSize=10)\nvectorizer_model = vectorizer.fit(removed)\nvectorized = vectorizer_model.transform(removed)\nvectorized.select(\"words_removed\", \"words_vectorized\").head(5)\n\n# **Note:** Our vocabulary seems more reasonable now. Although the problems with punctuation remain\nlist(enumerate(vectorizer_model.vocabulary))"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5eeff2ca-df7f-4727-a90f-94cef993e9ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: [(0, &#39;driver&#39;),\n (1, &#39;ride&#39;),\n (2, &#39;air&#39;),\n (3, &#39;ride.&#39;),\n (4, &#39;car&#39;),\n (5, &#39;really&#39;),\n (6, &#39;freshener&#39;),\n (7, &#39;vehicle&#39;),\n (8, &#39;due&#39;),\n (9, &#39;freshener.&#39;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: [(0, &#39;driver&#39;),\n (1, &#39;ride&#39;),\n (2, &#39;air&#39;),\n (3, &#39;ride.&#39;),\n (4, &#39;car&#39;),\n (5, &#39;really&#39;),\n (6, &#39;freshener&#39;),\n (7, &#39;vehicle&#39;),\n (8, &#39;due&#39;),\n (9, &#39;freshener.&#39;)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Selecting features\n\nWe have generated a potentially large number of features.  How do we distinguish the relevant features from the irrelevant ones?  Spark MLlib provides the [ChiSqSelector](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.ChiSqSelector.html#pyspark.ml.feature.ChiSqSelector) estimator to address this challenge when the label is categorical."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5ffd5f3-71c2-454c-963e-522c012d492b"}}},{"cell_type":"code","source":["# Use `ChiSqSelector` to select the top 5 features (probabaly too few to work well)\nfrom pyspark.ml.feature import ChiSqSelector\nselector = ChiSqSelector(featuresCol=\"words_vectorized\", labelCol=\"star_rating\", outputCol=\"words_selected\", numTopFeatures=5)\nselector_model = selector.fit(vectorized)\nselected = selector_model.transform(vectorized)\n\n# View reduced \nfor item in selected.select(\"words_removed\", \"words_selected\").head(5):\n    print (item[0], item[1])\n "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f37c688-50e1-4cbb-b14f-c921a0b29d17"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] (5,[],[])\n[&#39;junky&#39;, &#39;car.&#39;] (5,[],[])\n[&#39;awful&#39;, &#39;stench&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[1],[1.0])\n[&#39;trouble&#39;, &#39;note.&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;well!!&#39;] (5,[],[])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] (5,[],[])\n[&#39;junky&#39;, &#39;car.&#39;] (5,[],[])\n[&#39;awful&#39;, &#39;stench&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[1],[1.0])\n[&#39;trouble&#39;, &#39;note.&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;well!!&#39;] (5,[],[])\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# View reduced \nfor item in selected.select(\"words_removed\", \"words_selected\").head(50):\n    print (item[0], item[1])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b4bc903-4e93-4760-b1b5-841c671ae873"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] (5,[],[])\n[&#39;junky&#39;, &#39;car.&#39;] (5,[],[])\n[&#39;awful&#39;, &#39;stench&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[1],[1.0])\n[&#39;trouble&#39;, &#39;note.&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;well!!&#39;] (5,[],[])\n[&#39;really&#39;, &#39;irritating&#39;, &#39;driver&#39;, &#39;refused&#39;, &#39;cease&#39;, &#39;chatting!!&#39;] (5,[],[])\n[&#39;breathe&#39;, &#39;due&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[1,4],[1.0,1.0])\n[&#39;adequate&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;nicely!!&#39;] (5,[],[])\n[&#39;pleased&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;stereo&#39;, &#39;blaring&#39;] (5,[],[])\n[&#39;made&#39;, &#39;expected&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;polite&#39;, &#39;wanted&#39;, &#39;talk&#39;] (5,[],[])\n[&#39;delightful&#39;, &#39;ride&#39;] (5,[0],[1.0])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;super&#39;, &#39;well.&#39;] (5,[],[])\n[&#39;car&#39;, &#39;stunk!&#39;, &#39;duo&#39;, &#39;car&#39;, &#39;really&#39;, &#39;ban&#39;, &#39;air&#39;, &#39;fresheners&#39;, &#39;fragrances&#39;] (5,[1],[1.0])\n[&#39;lovely&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;fully&#39;, &#39;pleased&#39;] (5,[],[])\n[&#39;messy&#39;, &#39;car!&#39;, &#39;vacuum&#39;, &#39;mess.&#39;] (5,[],[])\n[&#39;gross&#39;, &#39;ride&#39;, &#39;due&#39;, &#39;really&#39;, &#39;reeking&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[0,1,4],[1.0,1.0,1.0])\n[&#39;marvelous&#39;, &#39;ride&#39;, &#39;friendly&#39;, &#39;driver&#39;] (5,[0],[1.0])\n[&#39;breathe&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[1],[1.0])\n[&#39;polite&#39;, &#39;driver!&#39;, &#39;refused&#39;, &#39;roll&#39;, &#39;windows&#39;, &#39;even&#39;, &#39;asked&#39;, &#39;to!&#39;] (5,[],[])\n[&#39;pleasing&#39;, &#39;ride&#39;] (5,[0],[1.0])\n[&#39;adequate&#39;, &#39;driver.&#39;] (5,[],[])\n[&#39;satisfactory&#39;, &#39;driver&#39;] (5,[],[])\n[&#39;completely&#39;, &#39;happy&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;air&#39;, &#39;freshener&#39;, &#39;vehicle&#39;, &#39;smelled&#39;] (5,[1,3],[1.0,1.0])\n[&#39;rough&#39;, &#39;ride!!!&#39;, &#39;driver&#39;, &#39;taught&#39;, &#39;drive!!!&#39;] (5,[],[])\n[&#39;michael&#39;, &#39;cease&#39;, &#39;chatting!&#39;, &#39;spoke&#39;, &#39;on.&#39;, &#39;want&#39;, &#39;chat.&#39;] (5,[],[])\n[&#39;superb&#39;, &#39;time&#39;, &#39;really&#39;, &#39;courteous&#39;, &#39;driver&#39;] (5,[],[])\n[&#39;thanks&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;happy&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;nasty&#39;, &#39;ride&#39;, &#39;due&#39;, &#39;reeking&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[0,1,4],[1.0,1.0,1.0])\n[&#39;driver&#39;, &#39;talk&#39;] (5,[],[])\n[&#39;pleased&#39;, &#39;ride&#39;, &#39;quite&#39;, &#39;fine&#39;, &#39;time&#39;] (5,[0],[1.0])\n[&#39;exceptional&#39;, &#39;service.&#39;] (5,[],[])\n[&#39;happy&#39;, &#39;ride&#39;, &#39;nice&#39;, &#39;time&#39;] (5,[0],[1.0])\n[&#39;perfectly&#39;, &#39;pleased!&#39;] (5,[],[])\n[&#39;ride&#39;, &#39;ok&#39;] (5,[0],[1.0])\n[&#39;totally&#39;, &#39;ok&#39;, &#39;time&#39;] (5,[],[])\n[&#39;pleasing&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;music&#39;, &#39;noisy&#39;, &#39;hear&#39;, &#39;driver&#39;, &#39;saying&#39;] (5,[],[])\n[&#39;awful&#39;, &#39;stink&#39;, &#39;world!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[1],[1.0])\n[&#39;jeremiah&#39;, &#39;drives&#39;, &#39;super&#39;, &#39;nicely!!&#39;] (5,[],[])\n[&#39;ride&#39;, &#39;decent&#39;, &#39;enough.&#39;] (5,[0],[1.0])\n[&#39;driver&#39;, &#39;attempted&#39;, &#39;speak&#39;] (5,[],[])\n[&#39;worst&#39;, &#39;odor&#39;, &#39;ever!&#39;, &#39;pitch&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[1],[1.0])\n[&#39;karli&#39;, &#39;drives&#39;, &#39;super&#39;, &#39;well!!!&#39;] (5,[],[])\n[&#39;pleased&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial.&#39;] (5,[],[])\n[&#39;junky&#39;, &#39;car.&#39;] (5,[],[])\n[&#39;awful&#39;, &#39;stench&#39;, &#39;time!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[1],[1.0])\n[&#39;trouble&#39;, &#39;note.&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;well!!&#39;] (5,[],[])\n[&#39;really&#39;, &#39;irritating&#39;, &#39;driver&#39;, &#39;refused&#39;, &#39;cease&#39;, &#39;chatting!!&#39;] (5,[],[])\n[&#39;breathe&#39;, &#39;due&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[1,4],[1.0,1.0])\n[&#39;adequate&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;nicely!!&#39;] (5,[],[])\n[&#39;pleased&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;stereo&#39;, &#39;blaring&#39;] (5,[],[])\n[&#39;made&#39;, &#39;expected&#39;] (5,[],[])\n[&#39;driver&#39;, &#39;polite&#39;, &#39;wanted&#39;, &#39;talk&#39;] (5,[],[])\n[&#39;delightful&#39;, &#39;ride&#39;] (5,[0],[1.0])\n[&#39;driver&#39;, &#39;drove&#39;, &#39;super&#39;, &#39;well.&#39;] (5,[],[])\n[&#39;car&#39;, &#39;stunk!&#39;, &#39;duo&#39;, &#39;car&#39;, &#39;really&#39;, &#39;ban&#39;, &#39;air&#39;, &#39;fresheners&#39;, &#39;fragrances&#39;] (5,[1],[1.0])\n[&#39;lovely&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;fully&#39;, &#39;pleased&#39;] (5,[],[])\n[&#39;messy&#39;, &#39;car!&#39;, &#39;vacuum&#39;, &#39;mess.&#39;] (5,[],[])\n[&#39;gross&#39;, &#39;ride&#39;, &#39;due&#39;, &#39;really&#39;, &#39;reeking&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[0,1,4],[1.0,1.0,1.0])\n[&#39;marvelous&#39;, &#39;ride&#39;, &#39;friendly&#39;, &#39;driver&#39;] (5,[0],[1.0])\n[&#39;breathe&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[1],[1.0])\n[&#39;polite&#39;, &#39;driver!&#39;, &#39;refused&#39;, &#39;roll&#39;, &#39;windows&#39;, &#39;even&#39;, &#39;asked&#39;, &#39;to!&#39;] (5,[],[])\n[&#39;pleasing&#39;, &#39;ride&#39;] (5,[0],[1.0])\n[&#39;adequate&#39;, &#39;driver.&#39;] (5,[],[])\n[&#39;satisfactory&#39;, &#39;driver&#39;] (5,[],[])\n[&#39;completely&#39;, &#39;happy&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;air&#39;, &#39;freshener&#39;, &#39;vehicle&#39;, &#39;smelled&#39;] (5,[1,3],[1.0,1.0])\n[&#39;rough&#39;, &#39;ride!!!&#39;, &#39;driver&#39;, &#39;taught&#39;, &#39;drive!!!&#39;] (5,[],[])\n[&#39;michael&#39;, &#39;cease&#39;, &#39;chatting!&#39;, &#39;spoke&#39;, &#39;on.&#39;, &#39;want&#39;, &#39;chat.&#39;] (5,[],[])\n[&#39;superb&#39;, &#39;time&#39;, &#39;really&#39;, &#39;courteous&#39;, &#39;driver&#39;] (5,[],[])\n[&#39;thanks&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;happy&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;nasty&#39;, &#39;ride&#39;, &#39;due&#39;, &#39;reeking&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[0,1,4],[1.0,1.0,1.0])\n[&#39;driver&#39;, &#39;talk&#39;] (5,[],[])\n[&#39;pleased&#39;, &#39;ride&#39;, &#39;quite&#39;, &#39;fine&#39;, &#39;time&#39;] (5,[0],[1.0])\n[&#39;exceptional&#39;, &#39;service.&#39;] (5,[],[])\n[&#39;happy&#39;, &#39;ride&#39;, &#39;nice&#39;, &#39;time&#39;] (5,[0],[1.0])\n[&#39;perfectly&#39;, &#39;pleased!&#39;] (5,[],[])\n[&#39;ride&#39;, &#39;ok&#39;] (5,[0],[1.0])\n[&#39;totally&#39;, &#39;ok&#39;, &#39;time&#39;] (5,[],[])\n[&#39;pleasing&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n[&#39;music&#39;, &#39;noisy&#39;, &#39;hear&#39;, &#39;driver&#39;, &#39;saying&#39;] (5,[],[])\n[&#39;awful&#39;, &#39;stink&#39;, &#39;world!&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener.&#39;] (5,[1],[1.0])\n[&#39;jeremiah&#39;, &#39;drives&#39;, &#39;super&#39;, &#39;nicely!!&#39;] (5,[],[])\n[&#39;ride&#39;, &#39;decent&#39;, &#39;enough.&#39;] (5,[0],[1.0])\n[&#39;driver&#39;, &#39;attempted&#39;, &#39;speak&#39;] (5,[],[])\n[&#39;worst&#39;, &#39;odor&#39;, &#39;ever!&#39;, &#39;pitch&#39;, &#39;air&#39;, &#39;freshener!&#39;] (5,[1],[1.0])\n[&#39;karli&#39;, &#39;drives&#39;, &#39;super&#39;, &#39;well!!!&#39;] (5,[],[])\n[&#39;pleased&#39;, &#39;ride.&#39;] (5,[2],[1.0])\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# List selected words:\n[vectorizer_model.vocabulary[i] for i in selector_model.selectedFeatures]"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"652070d8-24f1-4a4b-8cef-2cca372b3b7c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: [&#39;ride&#39;, &#39;air&#39;, &#39;ride.&#39;, &#39;freshener&#39;, &#39;due&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: [&#39;ride&#39;, &#39;air&#39;, &#39;ride.&#39;, &#39;freshener&#39;, &#39;due&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# `ChiSqSelector` does not provide any information on relative strength or\n# direction of the predictive relationships.  We can use some Spark SQL\n# to compute the average ride rating based on the presence or absence of each\n# vocabulary word in a review\n\nfrom pyspark.sql.functions import array_contains, count, mean\nfor word in vectorizer_model.vocabulary:\n  print (\"**** word = %s ****\\n\" % word)\n  vectorized \\\n    .select(array_contains(\"words_removed\", word).alias(\"contains_word\"), \"star_rating\") \\\n    .groupBy(\"contains_word\") \\\n    .agg(count(\"star_rating\"), mean(\"star_rating\")) \\\n    .show()\n\n# These results appear to be consistent with the results of `ChiSqSelector`\n"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38279db2-263b-4765-9783-87181bf625af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">**** word = driver ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               477|2.6624737945492662|\n|        false|              1345|3.0438661710037174|\n+-------------+------------------+------------------+\n\n**** word = ride ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               380|2.7342105263157896|\n|        false|              1442|2.9993065187239942|\n+-------------+------------------+------------------+\n\n**** word = air ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               321|1.5950155763239875|\n|        false|              1501|3.2325116588940705|\n+-------------+------------------+------------------+\n\n**** word = ride. ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               168|3.8511904761904763|\n|        false|              1654| 2.851874244256348|\n+-------------+------------------+------------------+\n\n**** word = car ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               158|2.4430379746835444|\n|        false|              1664|2.9915865384615383|\n+-------------+------------------+------------------+\n\n**** word = really ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               147|2.9863945578231292|\n|        false|              1675|2.9402985074626864|\n+-------------+------------------+------------------+\n\n**** word = freshener ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               140|1.5785714285714285|\n|        false|              1682| 3.057669441141498|\n+-------------+------------------+------------------+\n\n**** word = vehicle ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               129|2.4031007751937983|\n|        false|              1693| 2.985233313644418|\n+-------------+------------------+------------------+\n\n**** word = due ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               114|1.5964912280701755|\n|        false|              1708|3.0339578454332554|\n+-------------+------------------+------------------+\n\n**** word = freshener. ****\n\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|                80|             1.675|\n|        false|              1742|3.0022962112514353|\n+-------------+------------------+------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">**** word = driver ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               477|2.6624737945492662|\n        false|              1345|3.0438661710037174|\n+-------------+------------------+------------------+\n\n**** word = ride ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               380|2.7342105263157896|\n        false|              1442|2.9993065187239942|\n+-------------+------------------+------------------+\n\n**** word = air ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               321|1.5950155763239875|\n        false|              1501|3.2325116588940705|\n+-------------+------------------+------------------+\n\n**** word = ride. ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               168|3.8511904761904763|\n        false|              1654| 2.851874244256348|\n+-------------+------------------+------------------+\n\n**** word = car ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               158|2.4430379746835444|\n        false|              1664|2.9915865384615383|\n+-------------+------------------+------------------+\n\n**** word = really ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               147|2.9863945578231292|\n        false|              1675|2.9402985074626864|\n+-------------+------------------+------------------+\n\n**** word = freshener ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               140|1.5785714285714285|\n        false|              1682| 3.057669441141498|\n+-------------+------------------+------------------+\n\n**** word = vehicle ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               129|2.4031007751937983|\n        false|              1693| 2.985233313644418|\n+-------------+------------------+------------------+\n\n**** word = due ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|               114|1.5964912280701755|\n        false|              1708|3.0339578454332554|\n+-------------+------------------+------------------+\n\n**** word = freshener. ****\n\n+-------------+------------------+------------------+\ncontains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n         true|                80|             1.675|\n        false|              1742|3.0022962112514353|\n+-------------+------------------+------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["Copied results of previous cell to make all of them visible \n**** word = driver ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               477|2.6624737945492662|\n|        false|              1345|3.0438661710037174|\n+-------------+------------------+------------------+\n\n**** word = ride ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               380|2.7342105263157896|\n|        false|              1442|2.9993065187239942|\n+-------------+------------------+------------------+\n\n**** word = air ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               321|1.5950155763239875|\n|        false|              1501|3.2325116588940705|\n+-------------+------------------+------------------+\n\n**** word = ride. ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               168|3.8511904761904763|\n|        false|              1654| 2.851874244256348|\n+-------------+------------------+------------------+\n\n**** word = car ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               158|2.4430379746835444|\n|        false|              1664|2.9915865384615383|\n+-------------+------------------+------------------+\n\n**** word = really ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               147|2.9863945578231292|\n|        false|              1675|2.9402985074626864|\n+-------------+------------------+------------------+\n\n**** word = freshener ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               140|1.5785714285714285|\n|        false|              1682| 3.057669441141498|\n+-------------+------------------+------------------+\n\n**** word = vehicle ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               129|2.4031007751937983|\n|        false|              1693| 2.985233313644418|\n+-------------+------------------+------------------+\n\n**** word = due ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|               114|1.5964912280701755|\n|        false|              1708|3.0339578454332554|\n+-------------+------------------+------------------+\n\n**** word = freshener. ****\n+-------------+------------------+------------------+\n|contains_word|count(star_rating)|  avg(star_rating)|\n+-------------+------------------+------------------+\n|         true|                80|             1.675|\n|        false|              1742|3.0022962112514353|\n+-------------+------------------+------------------+\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d2338da-7113-4591-9298-35613f435a81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-3231183002850899&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">1</span>\n<span class=\"ansi-red-fg\">    Copied results of previous cell to make all of them visible</span>\n           ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>","errorSummary":"<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-3231183002850899&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">1</span>\n<span class=\"ansi-red-fg\">    Copied results of previous cell to make all of them visible</span>\n           ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Predict ride ratings\n\nAs a preview of topics to come, let us build a Naive Bayes classifier to predict the ride rating from the word vector.  Before doing so, we need to preprocess the ride rating.\n\nClassification algorithms in Spark MLlib generally assume that the label is a zero-based integer.  Let us subtract one from the original star_rating to comply:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a86b0dd1-4dfe-4591-97c8-29cd33cb90ac"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\nindexed = selected.withColumn(\"star_rating_indexed\", col(\"star_rating\") - 1.0)\n"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4001ceb0-c9f5-4bd5-a845-bb64b7e031d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# We can examine the mapping by applying the `crosstab` method:\nindexed \\\n  .crosstab(\"star_rating\", \"star_rating_indexed\") \\\n  .orderBy(\"star_rating_star_rating_indexed\") \\\n  .show()"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15a68874-4029-4298-9257-faf4cbf3edc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------------------------------+---+---+---+---+---+\n|star_rating_star_rating_indexed|0.0|1.0|2.0|3.0|4.0|\n+-------------------------------+---+---+---+---+---+\n|                              1|419|  0|  0|  0|  0|\n|                              2|  0|469|  0|  0|  0|\n|                              3|  0|  0|320|  0|  0|\n|                              4|  0|  0|  0| 23|  0|\n|                              5|  0|  0|  0|  0|591|\n+-------------------------------+---+---+---+---+---+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------+---+---+---+---+---+\nstar_rating_star_rating_indexed|0.0|1.0|2.0|3.0|4.0|\n+-------------------------------+---+---+---+---+---+\n                              1|419|  0|  0|  0|  0|\n                              2|  0|469|  0|  0|  0|\n                              3|  0|  0|320|  0|  0|\n                              4|  0|  0|  0| 23|  0|\n                              5|  0|  0|  0|  0|591|\n+-------------------------------+---+---+---+---+---+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["\n"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8482a099-87e7-4faf-bc2f-a0dfd024a1d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Now we are ready to build a simple Naive Bayes classifier:\nfrom pyspark.ml.classification import NaiveBayes\nnaive_bayes = NaiveBayes(featuresCol=\"words_selected\", labelCol=\"star_rating_indexed\")\nreviews_with_prediction = naive_bayes.fit(indexed).transform(indexed)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39b01f53-fe20-459b-aec4-6ef9ff4629fd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Compute the *confusion matrix* via the `crosstab` method:\nreviews_with_prediction \\\n  .crosstab(\"prediction\", \"star_rating_indexed\") \\\n  .orderBy(\"prediction_star_rating_indexed\") \\\n  .show()"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd98ecfd-fc5b-43d4-b4cd-d109e1385fe5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------+---+---+---+---+---+\n|prediction_star_rating_indexed|0.0|1.0|2.0|3.0|4.0|\n+------------------------------+---+---+---+---+---+\n|                           0.0| 60| 44|  9|  0|  0|\n|                           1.0|102|103| 15|  1|  0|\n|                           4.0|257|322|296| 22|591|\n+------------------------------+---+---+---+---+---+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------+---+---+---+---+---+\nprediction_star_rating_indexed|0.0|1.0|2.0|3.0|4.0|\n+------------------------------+---+---+---+---+---+\n                           0.0| 60| 44|  9|  0|  0|\n                           1.0|102|103| 15|  1|  0|\n                           4.0|257|322|296| 22|591|\n+------------------------------+---+---+---+---+---+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Compute the accuracy of the model:\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n                                              labelCol=\"star_rating_indexed\", \\\n                                              metricName=\"accuracy\")\nevaluator.evaluate(reviews_with_prediction)\n\n# It looks like we have some more work to do to improve our model.\n# Five words will not suffice!\n# This model is only correct 41% of the time"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30536e5d-82bd-4fee-8169-b1973b754c9c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[20]: 0.4138309549945115</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: 0.4138309549945115</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Hands On\n\n![Hands-on](https://cis442f-open-data.s3.amazonaws.com/pictures/hands.png \"Hands-on\")\n\n\nI suggest you clone this notebook to work on these exercises. Then modify the code above as needed. \n\n#### Exercises\n\n(1) Use the `RegexTokenizer` transformer to more cleanly tokenize the reviews.\n\n(2) Determine if increasing the vocabulary size improves the solution.\n\n(3) Use the `HashingTF` estimator rather than the `CountVectorizer` estimator to generate the term-frequency vectors. `HashingTF` is a more efficient alternative to CountVectorizer (see discussion in references)\n\nWe could also seek to improve the model by\n- Using ngrams\n- Tuning of hyperparameters, training parameters, or prediction parameters\n- Trying other algorithms\n\n\n\n#### References\n\n[Good discussion about differences between the `HashingTF` and the `CountVectorizer` estimators](https://stackoverflow.com/questions/35205865/what-is-the-difference-between-hashingtf-and-countvectorizer-in-spark)\n\n[Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering)\n\n[Feature selection](https://en.wikipedia.org/wiki/Feature_selection)\n\n[Extracting, transforming, and selecting features](http://spark.apache.org/docs/latest/ml-features.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"907b5768-c26e-4003-a3ec-51d0198060c1"}}}],"metadata":{"kernelspec":{"display_name":"Spark 2.0.0 - Scala 2.11","language":"scala","name":"spark2-scala"},"language_info":{"mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","codemirror_mode":"text/x-scala","version":"2.11.8","file_extension":".scala"},"application/vnd.databricks.v1+notebook":{"notebookName":"11a. Feature Extraction","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":859002697310988}},"nbformat":4,"nbformat_minor":0}
