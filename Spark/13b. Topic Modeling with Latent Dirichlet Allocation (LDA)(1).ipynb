{"cells":[{"cell_type":"markdown","source":["### Topic Modeling with Latent Dirichlet Allocation (LDA)\n\nIn this notebook we use Latent Dirichlet Allocation (LDA) to look for topics in the ride reviews. It is based on material supplied by Cloudera under their Cloudera Academic Partner program and *Spark: The Definitive Guide* book by Bill Chambers and Matei Zaharia. \n\nTopics\n- Extracting and transforming features\n- Counting frequency of words\n- Specifying and fitting a topic model using LDA\n- Exploring topics identified by LDA\n- Specifying and fitting a topic model using LDA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f78ebf80-8adf-4eba-bc11-027b8fddaec4"}}},{"cell_type":"code","source":["# Read the ride review data\nreviews = spark.read.parquet(\"/mnt/cis442f-data/duocar/clean/ride_reviews/\")\nreviews.head(5) "],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea64e587-a0bc-44cb-88f0-4068a9ad2f7c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[1]: [Row(ride_id=&#39;0000000009&#39;, review=&#39;Dale is extremely cordial.&#39;),\n Row(ride_id=&#39;0000000037&#39;, review=&#39;Very junky car.&#39;),\n Row(ride_id=&#39;0000000071&#39;, review=&#39;most awful stench of all time! throw away your air freshener!&#39;),\n Row(ride_id=&#39;0000000083&#39;, review=&#39;No trouble of note.&#39;),\n Row(ride_id=&#39;0000000086&#39;, review=&#39;The driver drove so well!!&#39;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[1]: [Row(ride_id=&#39;0000000009&#39;, review=&#39;Dale is extremely cordial.&#39;),\n Row(ride_id=&#39;0000000037&#39;, review=&#39;Very junky car.&#39;),\n Row(ride_id=&#39;0000000071&#39;, review=&#39;most awful stench of all time! throw away your air freshener!&#39;),\n Row(ride_id=&#39;0000000083&#39;, review=&#39;No trouble of note.&#39;),\n Row(ride_id=&#39;0000000086&#39;, review=&#39;The driver drove so well!!&#39;)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Extracting and transforming features\n\nThe ride reviews are not in a form amenable to machine learning algorithms. Spark MLlib provides a number of feature extractors and feature transformers to preprocess the ride reviews into a form appropriate for modeling.\n\n\n**Parse the ride reviews**\n- Use the [RegexTokenizer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.RegexTokenizer.html) class to improve the tokenization\n- Use the [StopWordsRemover](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StopWordsRemover.html) class to remove common words"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b26690cb-3ae8-427a-ab1b-96ea622f84d6"}}},{"cell_type":"code","source":["# Use RegexTokenizer class to tokenize reviews (configured to remove punctuation)\nfrom pyspark.ml.feature import RegexTokenizer\ntokenizer = RegexTokenizer(inputCol=\"review\", outputCol=\"words\", gaps=False, pattern=\"[a-zA-z-']+\")\ntokenized = tokenizer.transform(reviews)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7196431-9d84-42d4-8883-18f8c4ccbbb2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Use StopWordsRemover to remove common words\nfrom pyspark.ml.feature import StopWordsRemover\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_removed\")\nremover.getStopWords()[:10]\nremoved = remover.transform(tokenized)\nfor row in removed.head(5):\n    print(row)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fbf90b48-96e4-46eb-9efd-d3b103b8a0f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Row(ride_id=&#39;0000000009&#39;, review=&#39;Dale is extremely cordial.&#39;, words=[&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial&#39;], words_removed=[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial&#39;])\nRow(ride_id=&#39;0000000037&#39;, review=&#39;Very junky car.&#39;, words=[&#39;very&#39;, &#39;junky&#39;, &#39;car&#39;], words_removed=[&#39;junky&#39;, &#39;car&#39;])\nRow(ride_id=&#39;0000000071&#39;, review=&#39;most awful stench of all time! throw away your air freshener!&#39;, words=[&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener&#39;], words_removed=[&#39;awful&#39;, &#39;stench&#39;, &#39;time&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener&#39;])\nRow(ride_id=&#39;0000000083&#39;, review=&#39;No trouble of note.&#39;, words=[&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note&#39;], words_removed=[&#39;trouble&#39;, &#39;note&#39;])\nRow(ride_id=&#39;0000000086&#39;, review=&#39;The driver drove so well!!&#39;, words=[&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well&#39;], words_removed=[&#39;driver&#39;, &#39;drove&#39;, &#39;well&#39;])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Row(ride_id=&#39;0000000009&#39;, review=&#39;Dale is extremely cordial.&#39;, words=[&#39;dale&#39;, &#39;is&#39;, &#39;extremely&#39;, &#39;cordial&#39;], words_removed=[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial&#39;])\nRow(ride_id=&#39;0000000037&#39;, review=&#39;Very junky car.&#39;, words=[&#39;very&#39;, &#39;junky&#39;, &#39;car&#39;], words_removed=[&#39;junky&#39;, &#39;car&#39;])\nRow(ride_id=&#39;0000000071&#39;, review=&#39;most awful stench of all time! throw away your air freshener!&#39;, words=[&#39;most&#39;, &#39;awful&#39;, &#39;stench&#39;, &#39;of&#39;, &#39;all&#39;, &#39;time&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;your&#39;, &#39;air&#39;, &#39;freshener&#39;], words_removed=[&#39;awful&#39;, &#39;stench&#39;, &#39;time&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener&#39;])\nRow(ride_id=&#39;0000000083&#39;, review=&#39;No trouble of note.&#39;, words=[&#39;no&#39;, &#39;trouble&#39;, &#39;of&#39;, &#39;note&#39;], words_removed=[&#39;trouble&#39;, &#39;note&#39;])\nRow(ride_id=&#39;0000000086&#39;, review=&#39;The driver drove so well!!&#39;, words=[&#39;the&#39;, &#39;driver&#39;, &#39;drove&#39;, &#39;so&#39;, &#39;well&#39;], words_removed=[&#39;driver&#39;, &#39;drove&#39;, &#39;well&#39;])\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Count the frequency of words in each review"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82999f6c-411b-4487-b134-b2a526fcc520"}}},{"cell_type":"code","source":["# Count the words\nfrom pyspark.ml.feature import CountVectorizer\nvectorizer = CountVectorizer(inputCol=\"words_removed\", outputCol=\"words_vectorized\", vocabSize=100)\nvectorizer_model = vectorizer.fit(removed)\nvectorized = vectorizer_model.transform(removed)\n# vectorized.head(5)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ecc9c6e-ed03-4c0e-b01c-e6162f15621a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Our vocabulary seems reasonable now\nprint(list(enumerate(vectorizer_model.vocabulary[:100])))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58ac2431-d636-4178-b513-21acb384a010"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[(0, &#39;ride&#39;), (1, &#39;driver&#39;), (2, &#39;air&#39;), (3, &#39;freshener&#39;), (4, &#39;car&#39;), (5, &#39;vehicle&#39;), (6, &#39;really&#39;), (7, &#39;time&#39;), (8, &#39;due&#39;), (9, &#39;experience&#39;), (10, &#39;happy&#39;), (11, &#39;service&#39;), (12, &#39;pleased&#39;), (13, &#39;fine&#39;), (14, &#34;driver&#39;s&#34;), (15, &#39;appreciate&#39;), (16, &#39;bad&#39;), (17, &#39;awful&#39;), (18, &#39;stunk&#39;), (19, &#39;conversation&#39;), (20, &#39;smelled&#39;), (21, &#39;drives&#39;), (22, &#39;super&#39;), (23, &#39;extremely&#39;), (24, &#39;reeked&#39;), (25, &#39;felt&#39;), (26, &#39;polite&#39;), (27, &#39;radio&#39;), (28, &#39;clean&#39;), (29, &#39;nice&#39;), (30, &#39;horrible&#39;), (31, &#39;marvelous&#39;), (32, &#39;refused&#39;), (33, &#39;windows&#39;), (34, &#39;breathe&#39;), (35, &#39;fresheners&#39;), (36, &#39;made&#39;), (37, &#39;wanted&#39;), (38, &#39;nicely&#39;), (39, &#39;terrible&#39;), (40, &#39;drove&#39;), (41, &#39;music&#39;), (42, &#39;good&#39;), (43, &#39;unpleasant&#39;), (44, &#39;talk&#39;), (45, &#39;loud&#39;), (46, &#39;tidy&#39;), (47, &#39;talking&#39;), (48, &#39;full&#39;), (49, &#39;constantly&#39;), (50, &#39;stereo&#39;), (51, &#39;whole&#39;), (52, &#39;superb&#39;), (53, &#39;great&#39;), (54, &#39;swell&#39;), (55, &#39;entire&#39;), (56, &#39;ok&#39;), (57, &#39;want&#39;), (58, &#39;uncomfortable&#39;), (59, &#39;excellent&#39;), (60, &#39;get&#39;), (61, &#39;exceptional&#39;), (62, &#39;considerate&#39;), (63, &#39;annoying&#39;), (64, &#39;perfectly&#39;), (65, &#39;gave&#39;), (66, &#39;chat&#39;), (67, &#39;chatting&#39;), (68, &#39;forever&#39;), (69, &#39;speak&#39;), (70, &#39;disrespectful&#39;), (71, &#39;kept&#39;), (72, &#39;pleasant&#39;), (73, &#39;terrific&#39;), (74, &#39;kind&#39;), (75, &#39;courteous&#39;), (76, &#39;enough&#39;), (77, &#39;inconsiderate&#39;), (78, &#39;thank&#39;), (79, &#39;decent&#39;), (80, &#39;chatted&#39;), (81, &#39;speaking&#39;), (82, &#39;acceptable&#39;), (83, &#39;irritating&#39;), (84, &#39;quit&#39;), (85, &#39;rude&#39;), (86, &#39;still&#39;), (87, &#39;cease&#39;), (88, &#39;give&#39;), (89, &#39;totally&#39;), (90, &#39;stop&#39;), (91, &#39;fully&#39;), (92, &#39;trying&#39;), (93, &#39;much&#39;), (94, &#39;without&#39;), (95, &#39;stopping&#39;), (96, &#39;well&#39;), (97, &#39;stink&#39;), (98, &#39;thanks&#39;), (99, &#39;turn&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(0, &#39;ride&#39;), (1, &#39;driver&#39;), (2, &#39;air&#39;), (3, &#39;freshener&#39;), (4, &#39;car&#39;), (5, &#39;vehicle&#39;), (6, &#39;really&#39;), (7, &#39;time&#39;), (8, &#39;due&#39;), (9, &#39;experience&#39;), (10, &#39;happy&#39;), (11, &#39;service&#39;), (12, &#39;pleased&#39;), (13, &#39;fine&#39;), (14, &#34;driver&#39;s&#34;), (15, &#39;appreciate&#39;), (16, &#39;bad&#39;), (17, &#39;awful&#39;), (18, &#39;stunk&#39;), (19, &#39;conversation&#39;), (20, &#39;smelled&#39;), (21, &#39;drives&#39;), (22, &#39;super&#39;), (23, &#39;extremely&#39;), (24, &#39;reeked&#39;), (25, &#39;felt&#39;), (26, &#39;polite&#39;), (27, &#39;radio&#39;), (28, &#39;clean&#39;), (29, &#39;nice&#39;), (30, &#39;horrible&#39;), (31, &#39;marvelous&#39;), (32, &#39;refused&#39;), (33, &#39;windows&#39;), (34, &#39;breathe&#39;), (35, &#39;fresheners&#39;), (36, &#39;made&#39;), (37, &#39;wanted&#39;), (38, &#39;nicely&#39;), (39, &#39;terrible&#39;), (40, &#39;drove&#39;), (41, &#39;music&#39;), (42, &#39;good&#39;), (43, &#39;unpleasant&#39;), (44, &#39;talk&#39;), (45, &#39;loud&#39;), (46, &#39;tidy&#39;), (47, &#39;talking&#39;), (48, &#39;full&#39;), (49, &#39;constantly&#39;), (50, &#39;stereo&#39;), (51, &#39;whole&#39;), (52, &#39;superb&#39;), (53, &#39;great&#39;), (54, &#39;swell&#39;), (55, &#39;entire&#39;), (56, &#39;ok&#39;), (57, &#39;want&#39;), (58, &#39;uncomfortable&#39;), (59, &#39;excellent&#39;), (60, &#39;get&#39;), (61, &#39;exceptional&#39;), (62, &#39;considerate&#39;), (63, &#39;annoying&#39;), (64, &#39;perfectly&#39;), (65, &#39;gave&#39;), (66, &#39;chat&#39;), (67, &#39;chatting&#39;), (68, &#39;forever&#39;), (69, &#39;speak&#39;), (70, &#39;disrespectful&#39;), (71, &#39;kept&#39;), (72, &#39;pleasant&#39;), (73, &#39;terrific&#39;), (74, &#39;kind&#39;), (75, &#39;courteous&#39;), (76, &#39;enough&#39;), (77, &#39;inconsiderate&#39;), (78, &#39;thank&#39;), (79, &#39;decent&#39;), (80, &#39;chatted&#39;), (81, &#39;speaking&#39;), (82, &#39;acceptable&#39;), (83, &#39;irritating&#39;), (84, &#39;quit&#39;), (85, &#39;rude&#39;), (86, &#39;still&#39;), (87, &#39;cease&#39;), (88, &#39;give&#39;), (89, &#39;totally&#39;), (90, &#39;stop&#39;), (91, &#39;fully&#39;), (92, &#39;trying&#39;), (93, &#39;much&#39;), (94, &#39;without&#39;), (95, &#39;stopping&#39;), (96, &#39;well&#39;), (97, &#39;stink&#39;), (98, &#39;thanks&#39;), (99, &#39;turn&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# We can see how the processed reviews are vectorized\nvectorized.select(\"words_removed\", \"words_vectorized\").head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5acc95c4-dbd8-4ea4-ad8a-e98661193b5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: [Row(words_removed=[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial&#39;], words_vectorized=SparseVector(100, {23: 1.0})),\n Row(words_removed=[&#39;junky&#39;, &#39;car&#39;], words_vectorized=SparseVector(100, {4: 1.0})),\n Row(words_removed=[&#39;awful&#39;, &#39;stench&#39;, &#39;time&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener&#39;], words_vectorized=SparseVector(100, {2: 1.0, 3: 1.0, 7: 1.0, 17: 1.0})),\n Row(words_removed=[&#39;trouble&#39;, &#39;note&#39;], words_vectorized=SparseVector(100, {})),\n Row(words_removed=[&#39;driver&#39;, &#39;drove&#39;, &#39;well&#39;], words_vectorized=SparseVector(100, {1: 1.0, 40: 1.0, 96: 1.0}))]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: [Row(words_removed=[&#39;dale&#39;, &#39;extremely&#39;, &#39;cordial&#39;], words_vectorized=SparseVector(100, {23: 1.0})),\n Row(words_removed=[&#39;junky&#39;, &#39;car&#39;], words_vectorized=SparseVector(100, {4: 1.0})),\n Row(words_removed=[&#39;awful&#39;, &#39;stench&#39;, &#39;time&#39;, &#39;throw&#39;, &#39;away&#39;, &#39;air&#39;, &#39;freshener&#39;], words_vectorized=SparseVector(100, {2: 1.0, 3: 1.0, 7: 1.0, 17: 1.0})),\n Row(words_removed=[&#39;trouble&#39;, &#39;note&#39;], words_vectorized=SparseVector(100, {})),\n Row(words_removed=[&#39;driver&#39;, &#39;drove&#39;, &#39;well&#39;], words_vectorized=SparseVector(100, {1: 1.0, 40: 1.0, 96: 1.0}))]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Specify and fit a topic model using LDA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11a5f233-3f91-4420-a234-cd7ea1778008"}}},{"cell_type":"code","source":["# Use the `LDA` class to specify an LDA model\nfrom pyspark.ml.clustering import LDA\nlda = LDA(featuresCol=\"words_vectorized\", k=9)\n\n# Use the `fit` method to fit the LDA model\nlda_model = lda.fit(vectorized)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca93bc84-0452-4b7b-b414-19a536ec174b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Explore the topics identified by LDA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b4de082-9cd1-40d0-ae75-83f87bed508a"}}},{"cell_type":"code","source":["# lda_model.describeTopics().show(truncate=False)\nlda_model.describeTopics().show()"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66fa7c87-da2e-4466-b15e-b82f2f6c37fb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+--------------------+--------------------+\n|topic|         termIndices|         termWeights|\n+-----+--------------------+--------------------+\n|    0|[90, 49, 11, 72, ...|[0.01233804038514...|\n|    1|[11, 59, 52, 9, 4...|[0.12427603722302...|\n|    2|[27, 45, 93, 41, ...|[0.14359815282664...|\n|    3|[2, 3, 4, 8, 14, ...|[0.16685897318617...|\n|    4|[50, 26, 1, 29, 9...|[0.09192115679844...|\n|    5|[33, 1, 71, 58, 3...|[0.11439660147973...|\n|    6|[0, 1, 15, 10, 12...|[0.31353005697997...|\n|    7|[1, 19, 49, 37, 3...|[0.16619760156807...|\n|    8|[1, 5, 6, 4, 9, 2...|[0.16394327857149...|\n+-----+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+--------------------+\ntopic|         termIndices|         termWeights|\n+-----+--------------------+--------------------+\n    0|[90, 49, 11, 72, ...|[0.01233804038514...|\n    1|[11, 59, 52, 9, 4...|[0.12427603722302...|\n    2|[27, 45, 93, 41, ...|[0.14359815282664...|\n    3|[2, 3, 4, 8, 14, ...|[0.16685897318617...|\n    4|[50, 26, 1, 29, 9...|[0.09192115679844...|\n    5|[33, 1, 71, 58, 3...|[0.11439660147973...|\n    6|[0, 1, 15, 10, 12...|[0.31353005697997...|\n    7|[1, 19, 49, 37, 3...|[0.16619760156807...|\n    8|[1, 5, 6, 4, 9, 2...|[0.16394327857149...|\n+-----+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["topics = lda_model.topicsMatrix()\nvocab = vectorizer_model.vocabulary\nwordNumbers = 10  # number of words per topic\n\n# Capture the data from the model's describeTopics() method\ntopics_data = (lda_model.describeTopics(maxTermsPerTopic = wordNumbers)).collect()\n\n# Extract the vocabulary associated with each term associated with each topic\ntopics = []\nterms = []\nterms_in_words = []\nweights = []\n\nfor row in topics_data:\n    words =[]\n    topics.append(row[0])\n    terms.append(row[1])\n    for term in (row[1]):\n        word = vocab[term]\n        words.append(word)\n    terms_in_words.append(words)    \n    weights.append(row[2])\n\n# Print vocuabulary for each topic discoverd by LDA\nfor topic in topics:\n    print ((\"Topic: \" + str(topics[topic])), end=\"  \")\n    print (terms_in_words[topic])\n    # print (weights[topic])\n\n# Note: If we were working with this sort of data a lot it would make sense to turn this sort of analysis into a function that we could call at will"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"482cf59e-6357-45fe-97b6-374e6e395354"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Topic: 0  [&#39;stop&#39;, &#39;constantly&#39;, &#39;service&#39;, &#39;pleasant&#39;, &#39;driver&#39;, &#39;superb&#39;, &#39;freshener&#39;, &#39;rude&#39;, &#39;want&#39;, &#39;nicely&#39;]\nTopic: 1  [&#39;service&#39;, &#39;excellent&#39;, &#39;superb&#39;, &#39;experience&#39;, &#39;good&#39;, &#39;thanks&#39;, &#39;great&#39;, &#39;thank&#39;, &#39;swell&#39;, &#39;fine&#39;]\nTopic: 2  [&#39;radio&#39;, &#39;loud&#39;, &#39;much&#39;, &#39;music&#39;, &#39;turn&#39;, &#34;driver&#39;s&#34;, &#39;inconsiderate&#39;, &#39;drove&#39;, &#39;bad&#39;, &#39;awful&#39;]\nTopic: 3  [&#39;air&#39;, &#39;freshener&#39;, &#39;car&#39;, &#39;due&#39;, &#34;driver&#39;s&#34;, &#39;vehicle&#39;, &#39;bad&#39;, &#39;ride&#39;, &#39;time&#39;, &#39;reeked&#39;]\nTopic: 4  [&#39;stereo&#39;, &#39;polite&#39;, &#39;driver&#39;, &#39;nice&#39;, &#39;fully&#39;, &#39;pleased&#39;, &#39;chat&#39;, &#39;loud&#39;, &#39;awful&#39;, &#39;good&#39;]\nTopic: 5  [&#39;windows&#39;, &#39;driver&#39;, &#39;kept&#39;, &#39;uncomfortable&#39;, &#39;refused&#39;, &#39;rude&#39;, &#39;inconsiderate&#39;, &#39;experience&#39;, &#39;ride&#39;, &#39;full&#39;]\nTopic: 6  [&#39;ride&#39;, &#39;driver&#39;, &#39;appreciate&#39;, &#39;happy&#39;, &#39;pleased&#39;, &#39;time&#39;, &#39;fine&#39;, &#39;service&#39;, &#39;acceptable&#39;, &#39;perfectly&#39;]\nTopic: 7  [&#39;driver&#39;, &#39;conversation&#39;, &#39;constantly&#39;, &#39;wanted&#39;, &#39;refused&#39;, &#39;annoying&#39;, &#39;trying&#39;, &#39;want&#39;, &#39;quit&#39;, &#39;talking&#39;]\nTopic: 8  [&#39;driver&#39;, &#39;vehicle&#39;, &#39;really&#39;, &#39;car&#39;, &#39;experience&#39;, &#39;drives&#39;, &#39;tidy&#39;, &#39;clean&#39;, &#39;nicely&#39;, &#39;enough&#39;]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Topic: 0  [&#39;stop&#39;, &#39;constantly&#39;, &#39;service&#39;, &#39;pleasant&#39;, &#39;driver&#39;, &#39;superb&#39;, &#39;freshener&#39;, &#39;rude&#39;, &#39;want&#39;, &#39;nicely&#39;]\nTopic: 1  [&#39;service&#39;, &#39;excellent&#39;, &#39;superb&#39;, &#39;experience&#39;, &#39;good&#39;, &#39;thanks&#39;, &#39;great&#39;, &#39;thank&#39;, &#39;swell&#39;, &#39;fine&#39;]\nTopic: 2  [&#39;radio&#39;, &#39;loud&#39;, &#39;much&#39;, &#39;music&#39;, &#39;turn&#39;, &#34;driver&#39;s&#34;, &#39;inconsiderate&#39;, &#39;drove&#39;, &#39;bad&#39;, &#39;awful&#39;]\nTopic: 3  [&#39;air&#39;, &#39;freshener&#39;, &#39;car&#39;, &#39;due&#39;, &#34;driver&#39;s&#34;, &#39;vehicle&#39;, &#39;bad&#39;, &#39;ride&#39;, &#39;time&#39;, &#39;reeked&#39;]\nTopic: 4  [&#39;stereo&#39;, &#39;polite&#39;, &#39;driver&#39;, &#39;nice&#39;, &#39;fully&#39;, &#39;pleased&#39;, &#39;chat&#39;, &#39;loud&#39;, &#39;awful&#39;, &#39;good&#39;]\nTopic: 5  [&#39;windows&#39;, &#39;driver&#39;, &#39;kept&#39;, &#39;uncomfortable&#39;, &#39;refused&#39;, &#39;rude&#39;, &#39;inconsiderate&#39;, &#39;experience&#39;, &#39;ride&#39;, &#39;full&#39;]\nTopic: 6  [&#39;ride&#39;, &#39;driver&#39;, &#39;appreciate&#39;, &#39;happy&#39;, &#39;pleased&#39;, &#39;time&#39;, &#39;fine&#39;, &#39;service&#39;, &#39;acceptable&#39;, &#39;perfectly&#39;]\nTopic: 7  [&#39;driver&#39;, &#39;conversation&#39;, &#39;constantly&#39;, &#39;wanted&#39;, &#39;refused&#39;, &#39;annoying&#39;, &#39;trying&#39;, &#39;want&#39;, &#39;quit&#39;, &#39;talking&#39;]\nTopic: 8  [&#39;driver&#39;, &#39;vehicle&#39;, &#39;really&#39;, &#39;car&#39;, &#39;experience&#39;, &#39;drives&#39;, &#39;tidy&#39;, &#39;clean&#39;, &#39;nicely&#39;, &#39;enough&#39;]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Apply the topic model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2bddae2-890c-46af-8a7a-afa75c960bce"}}},{"cell_type":"code","source":["reviews_with_topics = lda_model.transform(vectorized)\nfor row in reviews_with_topics.select(\"review\", \"topicDistribution\").head(15):\n    print (row)"],"metadata":{"format":"text/plain","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04ac5470-6858-4926-88bb-552620928e8a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Row(review=&#39;Dale is extremely cordial.&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.0591, 0.5608, 0.0511, 0.065, 0.0535, 0.058]))\nRow(review=&#39;Very junky car.&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.5673, 0.0524, 0.0511, 0.065, 0.0534, 0.058]))\nRow(review=&#39;most awful stench of all time! throw away your air freshener!&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.8287, 0.0208, 0.0202, 0.0258, 0.0212, 0.023]))\nRow(review=&#39;No trouble of note.&#39;, topicDistribution=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))\nRow(review=&#39;The driver drove so well!!&#39;, topicDistribution=DenseVector([0.0249, 0.0253, 0.0254, 0.0293, 0.026, 0.0254, 0.0322, 0.0265, 0.785]))\nRow(review=&#39;really irritating driver refused to cease chatting!!&#39;, topicDistribution=DenseVector([0.0142, 0.0144, 0.0145, 0.0167, 0.0148, 0.0144, 0.0184, 0.8763, 0.0164]))\nRow(review=&#39;I could not breathe due to the air freshener.&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.8287, 0.0208, 0.0202, 0.0257, 0.0212, 0.023]))\nRow(review=&#39;just adequate&#39;, topicDistribution=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))\nRow(review=&#39;the driver drove so nicely!!&#39;, topicDistribution=DenseVector([0.0249, 0.0253, 0.0254, 0.0293, 0.026, 0.0254, 0.0322, 0.0265, 0.785]))\nRow(review=&#39;Pleased with this ride.&#39;, topicDistribution=DenseVector([0.0333, 0.0339, 0.034, 0.0391, 0.0348, 0.0339, 0.7172, 0.0354, 0.0384]))\nRow(review=&#39;The stereo was blaring&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.059, 0.5608, 0.0511, 0.065, 0.0534, 0.058]))\nRow(review=&#39;I made it there as expected&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.0591, 0.0524, 0.0511, 0.5733, 0.0534, 0.058]))\nRow(review=&#39;this driver was not polite and wanted to talk on and on&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.0234, 0.2582, 0.0202, 0.0258, 0.589, 0.023]))\nRow(review=&#39;It was a delightful ride&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.059, 0.0524, 0.0511, 0.5734, 0.0534, 0.058]))\nRow(review=&#39;The driver drove super well.&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.0234, 0.0208, 0.0202, 0.0257, 0.0212, 0.8283]))\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Row(review=&#39;Dale is extremely cordial.&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.0591, 0.5608, 0.0511, 0.065, 0.0535, 0.058]))\nRow(review=&#39;Very junky car.&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.5673, 0.0524, 0.0511, 0.065, 0.0534, 0.058]))\nRow(review=&#39;most awful stench of all time! throw away your air freshener!&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.8287, 0.0208, 0.0202, 0.0258, 0.0212, 0.023]))\nRow(review=&#39;No trouble of note.&#39;, topicDistribution=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))\nRow(review=&#39;The driver drove so well!!&#39;, topicDistribution=DenseVector([0.0249, 0.0253, 0.0254, 0.0293, 0.026, 0.0254, 0.0322, 0.0265, 0.785]))\nRow(review=&#39;really irritating driver refused to cease chatting!!&#39;, topicDistribution=DenseVector([0.0142, 0.0144, 0.0145, 0.0167, 0.0148, 0.0144, 0.0184, 0.8763, 0.0164]))\nRow(review=&#39;I could not breathe due to the air freshener.&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.8287, 0.0208, 0.0202, 0.0257, 0.0212, 0.023]))\nRow(review=&#39;just adequate&#39;, topicDistribution=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))\nRow(review=&#39;the driver drove so nicely!!&#39;, topicDistribution=DenseVector([0.0249, 0.0253, 0.0254, 0.0293, 0.026, 0.0254, 0.0322, 0.0265, 0.785]))\nRow(review=&#39;Pleased with this ride.&#39;, topicDistribution=DenseVector([0.0333, 0.0339, 0.034, 0.0391, 0.0348, 0.0339, 0.7172, 0.0354, 0.0384]))\nRow(review=&#39;The stereo was blaring&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.059, 0.5608, 0.0511, 0.065, 0.0534, 0.058]))\nRow(review=&#39;I made it there as expected&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.0591, 0.0524, 0.0511, 0.5733, 0.0534, 0.058]))\nRow(review=&#39;this driver was not polite and wanted to talk on and on&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.0234, 0.2582, 0.0202, 0.0258, 0.589, 0.023]))\nRow(review=&#39;It was a delightful ride&#39;, topicDistribution=DenseVector([0.0503, 0.0511, 0.0513, 0.059, 0.0524, 0.0511, 0.5734, 0.0534, 0.058]))\nRow(review=&#39;The driver drove super well.&#39;, topicDistribution=DenseVector([0.0199, 0.0202, 0.0203, 0.0234, 0.0208, 0.0202, 0.0257, 0.0212, 0.8283]))\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Hands On\n\n![Hands-on](https://cis442f-open-data.s3.amazonaws.com/pictures/hands.png \"Hands-on\")\n\n\n#### Exercises\n\n(1) Determine if increasing the vocabulary size improves the solution.\n\n(2) Experiment with different hyperparameters for the LDA algorithm.\n\n(3) Use the `HashingTF` estimator rather than the `CountVectorizer` estimator to generate the term-frequency vectors.\n\n(4) Use the `NGram` transformer to consider pairs of words rather than single words.\n\n\n\n**References**\n\n[Wikipedia - Latent Dirichlet allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)\n\n[Spark Documentation - Latent Dirichlet allocation](http://spark.apache.org/docs/latest/ml-clustering.html#latent-dirichlet-allocation-lda)\n\n[Spark Python API - LDA, LDAModel, localLDAModel, and DistributedLDAModel classes](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#clustering)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d23e3ea7-591f-4525-abfa-96f33a07a841"}}}],"metadata":{"kernelspec":{"display_name":"Spark 2.0.0 - Scala 2.11","language":"scala","name":"spark2-scala"},"language_info":{"mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","codemirror_mode":"text/x-scala","version":"2.11.8","file_extension":".scala"},"application/vnd.databricks.v1+notebook":{"notebookName":"13b. Topic Modeling with Latent Dirichlet Allocation (LDA)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":759379118593446}},"nbformat":4,"nbformat_minor":0}
